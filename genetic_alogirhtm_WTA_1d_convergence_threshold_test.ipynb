{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import copy\n",
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "params = {'legend.fontsize': 20,\n",
    "          'figure.figsize': (15, 5),\n",
    "         'axes.labelsize': 25,\n",
    "         'axes.titlesize':20,\n",
    "         'xtick.labelsize': 20,\n",
    "         'ytick.labelsize':20}\n",
    "\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read example file\n",
    "def read_example_file(filename):\n",
    "    with open(filename) as fp:\n",
    "        prob_setting = list(map(lambda x: int(x), fp.readline().split()))\n",
    "        if len(prob_setting) == 1:\n",
    "            n_targets, n_weapons = prob_setting[0], prob_setting[0]\n",
    "        else:\n",
    "            n_targets, n_weapons = prob_setting\n",
    "\n",
    "        values = []\n",
    "        for i in range(n_targets):\n",
    "            values.append(float(fp.readline()))\n",
    "\n",
    "        probabilities = []\n",
    "        for i in range(n_weapons):\n",
    "            probabilities.append([])\n",
    "            for j in range(n_targets):\n",
    "                probabilities[i].append(float(fp.readline()))\n",
    "    return n_targets, n_weapons, values, probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check convergence\n",
    "def check_convergence(population, threshold):\n",
    "    assignment_dict = {}\n",
    "    for assignment in population:\n",
    "        assignment = tuple(assignment)\n",
    "        if assignment not in assignment_dict:\n",
    "            assignment_dict[assignment] = 0\n",
    "        assignment_dict[assignment] += 1\n",
    "    for assignment in assignment_dict:\n",
    "        if assignment_dict[assignment] >= len(population) * threshold:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN-related code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Take in n by m matrix, convert it to 1D feature vector '''\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, n, m, embedding_size=8, units=64):\n",
    "        super(DQN, self).__init__()\n",
    "        # The assignment becomes embedded, so it has size m * embedding_size\n",
    "        # when flattened\n",
    "        # The n comes from the values attached\n",
    "        self.assignment_size = m * embedding_size\n",
    "        self.input_size = self.assignment_size + n\n",
    "        self.output_size = m * n\n",
    "        self.n = n\n",
    "        self.m = m\n",
    "    \n",
    "        self.embedding_size = embedding_size\n",
    "        # Embed the targets, since the actual numerical value of the\n",
    "        # targets don't mean anything\n",
    "        # Another idea: skip the middleman and replace the targets\n",
    "        # with the target values\n",
    "        self.embedding = nn.Embedding(n, self.embedding_size)\n",
    "        self.lin1 = nn.Linear(self.input_size, units)\n",
    "        self.drop1 = nn.Dropout(0.2)\n",
    "        self.lin2 = nn.Linear(units, self.output_size)\n",
    "        self.drop2 = nn.Dropout(0.2)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, state):\n",
    "        assignment = state[:, :self.m].long()\n",
    "        assignment = self.embedding(assignment)\n",
    "        \n",
    "        values = state[:, self.m:].float()\n",
    "                \n",
    "        # Flatten the assignment embedding\n",
    "        assignment = assignment.view(-1, self.assignment_size).float() \n",
    "        \n",
    "        # and concatenate the values\n",
    "        x = torch.cat([assignment, values], dim=1)\n",
    "        \n",
    "        x = F.relu(self.drop1(self.lin1(x)))\n",
    "        x = F.relu(self.lin2(x))\n",
    "        return x\n",
    "\n",
    "# with dueling networks\n",
    "class DuelingDQN(nn.Module):\n",
    "\n",
    "    def __init__(self, n, m, embedding_size=8, units=128):\n",
    "        super(DuelingDQN, self).__init__()\n",
    "        # The assignment becomes embedded, so it has size m * embedding_size\n",
    "        # when flattened\n",
    "        # The n comes from the values attached\n",
    "        self.assignment_size = m * embedding_size\n",
    "        self.input_size = self.assignment_size + n\n",
    "        self.output_size = m * n\n",
    "        self.n = n\n",
    "        self.m = m\n",
    "      \n",
    "        self.units = units\n",
    "\n",
    "        self.embedding_size = embedding_size\n",
    "        # Embed the targets, since the actual numerical value of the\n",
    "        # targets don't mean anything\n",
    "        # Another idea: skip the middleman and replace the targets\n",
    "        # with the target values\n",
    "        self.embedding = nn.Embedding(n, self.embedding_size)\n",
    "        self.lin1 = nn.Linear(self.input_size, units)\n",
    "        self.drop1 = nn.Dropout(0.2)\n",
    "\n",
    "        # Layer to measure the value of a state\n",
    "        self.value_stream = nn.Sequential(\n",
    "            nn.Linear(units, units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(units, 1)\n",
    "        )\n",
    "        # Layer to measure the advantages of an action given a state\n",
    "        self.advantage_stream = nn.Sequential(\n",
    "            nn.Linear(units, units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(units, self.output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, state):\n",
    "        assignment = state[:, :self.m].long()\n",
    "        assignment = self.embedding(assignment)\n",
    "\n",
    "\n",
    "        values = state[:, self.m:].float()\n",
    "\n",
    "        # Flatten the assignment embedding\n",
    "        assignment = assignment.view(-1, self.assignment_size).float() \n",
    "        \n",
    "        # and concatenate the values\n",
    "        x = torch.cat([assignment, values], dim=1)\n",
    "        x = F.relu(self.drop1(self.lin1(x)))\n",
    "        values = self.value_stream(x)\n",
    "        advantages = self.advantage_stream(x)\n",
    "        qvals = values + (advantages - advantages.mean())\n",
    "        \n",
    "        return qvals\n",
    "\n",
    "    def feature_size(self):\n",
    "        return self.conv(autograd.Variable(torch.zeros(1, *self.input_dim))).view(1, -1).size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_possible(state, weapon, target):\n",
    "    '''\n",
    "    We don't want to assign a weapon to the target if it is already assigned\n",
    "    to the target, since this does not change the state at all.\n",
    "    '''\n",
    "    curr_target = state[weapon].item()\n",
    "    return curr_target != target \n",
    "\n",
    "def select_action(model, state, n):\n",
    "    # state: 1 * (n + m) tensor\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        state_batch = torch.unsqueeze(state, 1).transpose(0, 1).float()\n",
    "        largest = torch.sort(model(state_batch), descending=True, dim=1)[1]\n",
    "        model.train()\n",
    "\n",
    "        # Try until we get a valid action\n",
    "        for i in largest[0]:\n",
    "            weapon = i / n\n",
    "            target = i % n\n",
    "\n",
    "            if is_possible(state, weapon.item(), target.item()):\n",
    "                return torch.tensor([i], device=device)\n",
    "\n",
    "        # This should never happen\n",
    "        raise ValueError('Invalid state: no possible action')\n",
    "        \n",
    "def decode_action(action, n):\n",
    "        '''\n",
    "        Given an action, return the weapon and target associated with\n",
    "        that action.\n",
    "        '''\n",
    "        return action // n, action % n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WTA_1D_General_GA:\n",
    "    def __init__(self, config, example_number, mutation_method='random'):\n",
    "        self.config = config\n",
    "        # n_targets: number of targets, n_weapons: number of weapons\n",
    "        # values: list of target values (size: n_targets)\n",
    "        # probabilities: list of destruction probabilities (size: n_weapons x n_targets)\n",
    "        self.n_targets, self.n_weapons, self.values, self.probabilities = read_example_file(config['example_file'])\n",
    "        # state: list of assignments (size: population_size x n_weapons, 0-indexed for target of each weapon)\n",
    "        self.state = self.generate_initial_population(config['population_size'])\n",
    "        self.good_gene_dict = self.get_good_gene_dict()\n",
    "        self.mutation_method = mutation_method\n",
    "        self.dqn_model = torch.load('./trained_models/WTA{}'.format(example_number), map_location=torch.device('cpu'))\n",
    "        self.dqn_model.eval()\n",
    "        self.dueling_dqn_model = torch.load('./trained_models/WTA{}_dueling'.format(example_number), map_location=torch.device('cpu'))\n",
    "        self.dueling_dqn_model.eval()\n",
    "    \n",
    "    # get the best target for each weapon (used for ex_crossover)\n",
    "    def get_good_gene_dict(self):\n",
    "        good_gene_dict = {}\n",
    "        for i in range(self.n_weapons):\n",
    "            weapon_target_edv_list = []\n",
    "            for j in range(self.n_targets):\n",
    "                weapon_target_edv_list.append(self.values[j] * self.probabilities[i][j])\n",
    "            good_gene = weapon_target_edv_list.index(max(weapon_target_edv_list))\n",
    "            good_gene_dict[i] = good_gene\n",
    "                \n",
    "        return good_gene_dict\n",
    "    \n",
    "    # update state after crossover\n",
    "    def ocp_crossover(self, population):\n",
    "        crossover_state = []\n",
    "        for _ in range(self.config['population_size']):\n",
    "            father, mother = random.sample(population, 2)\n",
    "            point = random.randint(0, self.n_weapons-1)\n",
    "            child = father[:point] + mother[point:]\n",
    "            crossover_state.append(child)\n",
    "        return crossover_state\n",
    "    \n",
    "    # ex crossover as explained in the paper\n",
    "    # repeat the following process for m_c < n_target times\n",
    "    # 1. find genes (weapon-target pair) with the same value of target in both parents\n",
    "    # 2. inherit good genes (good gene defined as the maximum target for each weapon)\n",
    "    # 3. randomly select two genes not inhereited from parents\n",
    "    # 4. exchange genes to generate offspring\n",
    "    def ex_crossover(self, population):\n",
    "        pool = []\n",
    "        population = copy.deepcopy(population)\n",
    "        for _ in range(self.config['n_offsprings'] // 2):\n",
    "            father, mother = random.sample(population, 2)\n",
    "            child1, child2 = father, mother\n",
    "            for _ in range(self.config['m_c']):\n",
    "                # step 2\n",
    "                inherited_gene_list = []\n",
    "                for i in range(self.n_weapons):\n",
    "                    if father[i] == mother[i] and father[i] == self.good_gene_dict[i]: # inherit to child\n",
    "                        inherited_gene_list.append(i)\n",
    "                gene_swap_candidates = set(range(self.n_weapons)) - set(inherited_gene_list)\n",
    "                if len(gene_swap_candidates) < 2:\n",
    "                    break\n",
    "\n",
    "                # step 3\n",
    "                swap_idx1, swap_idx2 = random.sample(gene_swap_candidates, 2)\n",
    "                child1[swap_idx1], child2[swap_idx2] = child2[swap_idx2], child1[swap_idx1]\n",
    "                child1[swap_idx2], child2[swap_idx1] = child2[swap_idx1], child1[swap_idx2]\n",
    "            \n",
    "            pool.append(child1)\n",
    "            pool.append(child2)\n",
    "        return pool\n",
    "\n",
    "    # update state after mutation\n",
    "    \"\"\"\n",
    "    def mutate(self, learner):\n",
    "        mutated_state = []\n",
    "        for assignment in self.state:\n",
    "            mutated_assignment = learner.get_mutation(assignment)\n",
    "            mutated_state.append(mutated_assignment)\n",
    "        self.state = mutated_state\n",
    "    \"\"\"\n",
    "    def mutate_random(self, population):\n",
    "        mutated_population = []\n",
    "        for assignment in population:\n",
    "            for _ in range(self.config['m_m']):\n",
    "                # choose random gene\n",
    "                mutated_weapon = random.sample(list(range(self.n_weapons)), 1)[0]\n",
    "                mutated_target = random.sample(list(range(self.n_targets)), 1)[0]\n",
    "                assignment[mutated_weapon] = mutated_target\n",
    "            mutated_population.append(assignment)\n",
    "        return mutated_population\n",
    "    \n",
    "    def mutate_dqn(self, population, model_type):\n",
    "        mutated_population = []\n",
    "        for assignment in population:\n",
    "            for _ in range(self.config['m_m']):\n",
    "                state = torch.tensor(np.concatenate([assignment, self.values]), device=torch.device('cpu'))\n",
    "                if model_type == 'dqn':\n",
    "                    action = select_action(self.dqn_model, state, self.n_weapons)\n",
    "                elif model_type == 'dueling_dqn':\n",
    "                    action = select_action(self.dueling_dqn_model, state, self.n_weapons)\n",
    "                mutated_weapon, mutated_target = decode_action(action, self.n_weapons)\n",
    "                mutated_weapon, mutated_target = mutated_weapon.numpy()[0], mutated_target.numpy()[0]\n",
    "                assignment[mutated_weapon] = mutated_target\n",
    "            mutated_population.append(assignment)\n",
    "        return mutated_population\n",
    "    \n",
    "    def reward(self, assignment):\n",
    "        survival_probabilities = [1] * self.n_targets\n",
    "        for i in range(self.n_weapons):\n",
    "            survival_probabilities[assignment[i]] *= 1 - self.probabilities[i][assignment[i]]\n",
    "        reward = 0\n",
    "        for j in range(self.n_targets):\n",
    "            reward += self.values[j] * (1 - survival_probabilities[j])\n",
    "        return reward\n",
    "    \n",
    "    # choose the best population from the pool of population + offspring\n",
    "    def evolution_strategy(self, pool):\n",
    "        pool = sorted(pool, key = lambda x: self.reward(x), reverse=True)\n",
    "        return pool[:self.config['population_size']]\n",
    "    \n",
    "    # helper functions\n",
    "    def generate_initial_population(self, population_size):\n",
    "        population = []\n",
    "        targets = list(range(self.n_targets))\n",
    "        for i in range(population_size):\n",
    "            assignment = [random.choice(targets) for _ in range(self.n_weapons)]\n",
    "            population.append(assignment)\n",
    "        return population\n",
    "    \n",
    "    def reset(self):\n",
    "        self.state = [-1] * self.n_weapons\n",
    "        \n",
    "    def run(self, max_iter, convergence_threshold=1.0, verbose=False, fp=None):\n",
    "        population = self.generate_initial_population(self.config['population_size'])\n",
    "#         print('initial population', population)\n",
    "        assert self.mutation_method in ['random', 'dqn', 'dueling_dqn']\n",
    "        for i_iter in range(max_iter):\n",
    "            pool = self.ex_crossover(population)\n",
    "            if self.mutation_method == 'random':\n",
    "                pool = self.mutate_random(pool)\n",
    "            elif self.mutation_method == 'dqn':\n",
    "                pool = self.mutate_dqn(pool, self.mutation_method)\n",
    "            elif self.mutation_method == 'dueling_dqn':\n",
    "                pool = self.mutate_dqn(pool, self.mutation_method)\n",
    "            population = self.evolution_strategy(pool + population)\n",
    "            \n",
    "            if fp is not None:\n",
    "                reward = max(map(lambda x: self.reward(x), population))\n",
    "                result = sorted(population, key = lambda x: self.reward(x), reverse=True)[0]\n",
    "                out_list = [str(i_iter + 1), '{:.2f}'.format(reward), '_'.join(map(lambda x: str(x), result))]\n",
    "                fp.write(','.join(out_list) + '\\n')\n",
    "            \n",
    "            # check convergence\n",
    "            if check_convergence(population, convergence_threshold):\n",
    "                if verbose:\n",
    "                    print('converged in iter {}'.format(i_iter+1))\n",
    "                break\n",
    "                \n",
    "            if verbose:\n",
    "                if (i_iter + 1) % 40 == 0:\n",
    "                    print('iter {}: reward = {:.2f}'.format(i_iter+1, max(map(lambda x: self.reward(x), population))))\n",
    "                    candidates = copy.deepcopy(population)\n",
    "                    candidates = sorted(candidates, key = lambda x: self.reward(x), reverse=True)\n",
    "                    print(candidates[0])\n",
    "        population = sorted(population, key = lambda x: self.reward(x), reverse=True)\n",
    "        return population[0], self.reward(population[0]), i_iter+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'example_file': './examples/WTA1',\n",
    "    'population_size': 50,\n",
    "    'n_offsprings': 50,\n",
    "    'm_c': 1,\n",
    "    'm_m': 1 # for fair comparison set m_m to 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converged in iter 16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([4, 3, 2, 1, 0], 328.636, 16)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wta_1d = WTA_1D_General_GA(config, 1, mutation_method='dqn')\n",
    "\n",
    "wta_1d.run(800, convergence_threshold=0.5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_WEAPONS = 20\n",
    "max_iter = 5000\n",
    "N_WTA = 3\n",
    "M_POPULATION = 15\n",
    "M_OFFSPRINGS = 10\n",
    "N_EXPERIMENTS = 8\n",
    "\n",
    "config = {\n",
    "    'example_file': './examples/WTA{}'.format(N_WTA),\n",
    "    'population_size': N_WEAPONS * M_POPULATION,\n",
    "    'n_offsprings': N_WEAPONS * M_OFFSPRINGS,\n",
    "    'm_c': 1,\n",
    "    'm_m': 1 # for fair comparison set m_m to 1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convergence threshold 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: [6, 1, 5, 8, 18, 2, 0, 17, 10, 12, 4, 19, 13, 9, 11, 3, 14, 7, 15, 16], reward: 945.548, convergence: 10000\n",
      "result: [19, 1, 5, 9, 18, 3, 2, 10, 7, 6, 17, 12, 13, 4, 11, 14, 8, 0, 15, 16], reward: 952.743, convergence: 10000\n",
      "result: [2, 1, 17, 9, 15, 3, 5, 10, 7, 12, 18, 19, 13, 4, 11, 6, 8, 0, 16, 14], reward: 957.366, convergence: 10000\n",
      "result: [18, 6, 11, 9, 1, 2, 5, 13, 10, 12, 3, 19, 14, 0, 4, 17, 8, 7, 15, 16], reward: 954.871, convergence: 10000\n",
      "result: [11, 1, 2, 8, 18, 3, 5, 10, 7, 12, 17, 19, 13, 9, 4, 6, 14, 0, 15, 16], reward: 955.313, convergence: 10000\n",
      "result: [2, 8, 17, 9, 15, 10, 5, 1, 7, 12, 3, 18, 13, 0, 4, 6, 14, 19, 16, 11], reward: 949.261, convergence: 10000\n",
      "result: [11, 6, 5, 9, 1, 18, 2, 8, 10, 12, 3, 19, 13, 4, 7, 17, 14, 0, 15, 16], reward: 951.999, convergence: 10000\n",
      "result: [2, 1, 11, 8, 0, 18, 3, 10, 7, 12, 17, 19, 13, 9, 4, 6, 14, 5, 15, 16], reward: 950.269, convergence: 10000\n",
      "result: [2, 7, 17, 9, 1, 19, 3, 8, 10, 0, 18, 12, 13, 4, 11, 6, 14, 5, 15, 16], reward: 948.896, convergence: 10000\n",
      "result: [18, 8, 5, 9, 1, 3, 4, 13, 10, 6, 7, 19, 2, 12, 11, 17, 14, 0, 15, 16], reward: 947.419, convergence: 10000\n"
     ]
    }
   ],
   "source": [
    "convergence_threshold = 0.5\n",
    "\n",
    "fpout = open('./experiments/convergence/WTA{}_random_threshold_{}_result.csv'.format(N_WTA, convergence_threshold), 'w')\n",
    "wr = csv.writer(fpout, delimiter=',')\n",
    "wr.writerow(['result', 'reward', 'convergence_iter'])\n",
    "\n",
    "for i_exp in range(N_EXPERIMENTS):\n",
    "    fpout_iter = open('./experiments/plot/WTA{}_random_threshold_{}_experiment{}.csv'.format(N_WTA, convergence_threshold, i_exp), 'w')\n",
    "    fpout_iter.write('i_iter,reward,result\\n')\n",
    "    \n",
    "    wta_1d = WTA_1D_General_GA(config, N_WTA, mutation_method='random')\n",
    "    result, reward, convergence_iter = wta_1d.run(max_iter, convergence_threshold=convergence_threshold, verbose=False, fp=fpout_iter)\n",
    "    \n",
    "    print('result: {}, reward: {:.3f}, convergence: {}'.format(result, reward, convergence_iter))\n",
    "    wr.writerow(['_'.join(map(lambda x: str(x), result)), '{:.3f}'.format(reward), convergence_iter])\n",
    "    \n",
    "    fpout_iter.close()\n",
    "        \n",
    "fpout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: [19, 1, 17, 10, 3, 18, 16, 13, 14, 12, 5, 4, 0, 15, 6, 2, 8, 7, 9, 11], reward: 905.870, convergence: 119\n",
      "result: [19, 2, 5, 10, 3, 18, 16, 11, 13, 12, 17, 4, 0, 15, 1, 6, 8, 7, 9, 14], reward: 906.487, convergence: 135\n",
      "result: [19, 6, 17, 10, 3, 18, 16, 11, 13, 12, 5, 4, 0, 15, 1, 2, 8, 7, 9, 14], reward: 899.738, convergence: 30\n",
      "result: [19, 6, 2, 9, 16, 18, 5, 13, 10, 12, 3, 4, 14, 0, 11, 17, 8, 7, 15, 1], reward: 952.806, convergence: 3881\n",
      "result: [13, 6, 17, 10, 19, 18, 9, 11, 14, 12, 3, 4, 0, 15, 1, 2, 8, 7, 16, 5], reward: 896.366, convergence: 70\n",
      "result: [19, 6, 2, 9, 3, 18, 5, 13, 10, 12, 17, 4, 14, 15, 11, 0, 8, 7, 16, 1], reward: 948.175, convergence: 2757\n",
      "result: [19, 6, 17, 10, 3, 18, 16, 13, 14, 12, 5, 4, 0, 15, 1, 2, 8, 7, 9, 11], reward: 905.486, convergence: 68\n",
      "result: [19, 6, 17, 10, 3, 18, 16, 13, 14, 12, 5, 4, 0, 15, 1, 2, 8, 7, 9, 11], reward: 905.486, convergence: 77\n",
      "result: [11, 6, 17, 9, 15, 18, 5, 13, 10, 12, 3, 4, 2, 0, 14, 2, 8, 7, 16, 1], reward: 926.836, convergence: 1825\n",
      "result: [19, 6, 2, 9, 3, 18, 5, 13, 10, 12, 17, 4, 14, 15, 11, 0, 8, 7, 16, 1], reward: 948.175, convergence: 2828\n"
     ]
    }
   ],
   "source": [
    "convergence_threshold = 0.5\n",
    "\n",
    "fpout = open('./experiments/convergence/WTA{}_dqn_threshold_{}_result.csv'.format(N_WTA, convergence_threshold), 'w')\n",
    "wr = csv.writer(fpout, delimiter=',')\n",
    "wr.writerow(['result', 'reward', 'convergence_iter'])\n",
    "\n",
    "for i_exp in range(N_EXPERIMENTS):\n",
    "    fpout_iter = open('./experiments/plot/WTA{}_dqn_threshold_{}_experiment{}.csv'.format(N_WTA, convergence_threshold, i_exp), 'w')\n",
    "    fpout_iter.write('i_iter,reward,result\\n')\n",
    "    \n",
    "    wta_1d = WTA_1D_General_GA(config, N_WTA, mutation_method='dqn')\n",
    "    result, reward, convergence_iter = wta_1d.run(max_iter, convergence_threshold=convergence_threshold, verbose=False, fp=fpout_iter)\n",
    "    \n",
    "    print('result: {}, reward: {:.3f}, convergence: {}'.format(result, reward, convergence_iter))\n",
    "    wr.writerow(['_'.join(map(lambda x: str(x), result)), '{:.3f}'.format(reward), convergence_iter])\n",
    "    \n",
    "    fpout_iter.close()\n",
    "        \n",
    "fpout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: [19, 0, 5, 11, 4, 2, 13, 1, 10, 6, 3, 12, 14, 8, 17, 15, 18, 9, 7, 16], reward: 882.168, convergence: 35\n",
      "result: [19, 0, 5, 8, 4, 2, 9, 1, 10, 15, 3, 12, 14, 11, 17, 6, 18, 13, 7, 16], reward: 892.451, convergence: 25\n",
      "result: [19, 6, 5, 9, 1, 2, 4, 13, 10, 0, 3, 12, 14, 18, 11, 17, 8, 7, 15, 16], reward: 946.660, convergence: 1309\n",
      "result: [19, 1, 5, 9, 18, 2, 3, 13, 10, 0, 17, 12, 14, 4, 11, 6, 8, 7, 15, 16], reward: 953.059, convergence: 4587\n",
      "result: [19, 1, 5, 9, 18, 2, 3, 13, 10, 6, 4, 12, 14, 0, 11, 17, 8, 7, 15, 16], reward: 952.873, convergence: 8260\n",
      "result: [19, 1, 5, 18, 17, 2, 3, 13, 10, 0, 4, 12, 14, 9, 11, 6, 8, 7, 17, 16], reward: 936.936, convergence: 1687\n",
      "result: [19, 7, 5, 9, 18, 2, 3, 13, 10, 6, 4, 12, 14, 1, 11, 15, 8, 0, 17, 16], reward: 941.305, convergence: 1372\n",
      "result: [19, 0, 5, 11, 4, 2, 9, 7, 10, 15, 3, 12, 14, 1, 17, 6, 8, 13, 18, 16], reward: 888.038, convergence: 46\n",
      "result: [19, 0, 5, 11, 4, 2, 9, 13, 10, 15, 3, 12, 14, 18, 17, 6, 8, 7, 17, 16], reward: 893.512, convergence: 39\n",
      "result: [19, 7, 5, 9, 18, 2, 3, 13, 10, 6, 4, 12, 14, 18, 11, 17, 8, 0, 15, 16], reward: 929.795, convergence: 824\n"
     ]
    }
   ],
   "source": [
    "convergence_threshold = 0.5\n",
    "\n",
    "fpout = open('./experiments/convergence/WTA{}_dueling-dqn_threshold_{}_result.csv'.format(N_WTA, convergence_threshold), 'w')\n",
    "wr = csv.writer(fpout, delimiter=',')\n",
    "wr.writerow(['result', 'reward', 'convergence_iter'])\n",
    "\n",
    "for i_exp in range(N_EXPERIMENTS):\n",
    "    fpout_iter = open('./experiments/plot/WTA{}_dueling-dqn_threshold_{}_experiment{}.csv'.format(N_WTA, convergence_threshold, i_exp), 'w')\n",
    "    fpout_iter.write('i_iter,reward,result\\n')\n",
    "    \n",
    "    wta_1d = WTA_1D_General_GA(config, N_WTA, mutation_method='dueling_dqn')\n",
    "    result, reward, convergence_iter = wta_1d.run(max_iter, convergence_threshold=convergence_threshold, verbose=False, fp=fpout_iter)\n",
    "    \n",
    "    print('result: {}, reward: {:.3f}, convergence: {}'.format(result, reward, convergence_iter))\n",
    "    wr.writerow(['_'.join(map(lambda x: str(x), result)), '{:.3f}'.format(reward), convergence_iter])\n",
    "    \n",
    "    fpout_iter.close()\n",
    "        \n",
    "fpout.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convergence threshold 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: [11, 1, 2, 8, 15, 3, 5, 13, 10, 0, 17, 12, 18, 9, 4, 6, 14, 7, 19, 16], reward: 948.350, convergence: 10000\n",
      "result: [18, 8, 5, 9, 1, 3, 4, 13, 10, 12, 17, 19, 2, 0, 11, 6, 14, 7, 15, 16], reward: 951.667, convergence: 10000\n",
      "result: [11, 6, 2, 9, 1, 10, 3, 17, 7, 12, 18, 19, 13, 0, 4, 14, 8, 5, 15, 16], reward: 951.071, convergence: 10000\n",
      "result: [11, 1, 2, 9, 15, 10, 3, 18, 7, 6, 4, 19, 13, 0, 14, 17, 8, 5, 16, 12], reward: 948.942, convergence: 10000\n",
      "result: [11, 1, 17, 18, 16, 2, 5, 8, 10, 12, 3, 19, 13, 9, 7, 6, 14, 0, 15, 4], reward: 949.475, convergence: 10000\n",
      "result: [6, 1, 11, 9, 3, 2, 5, 10, 7, 12, 17, 18, 13, 0, 4, 14, 8, 19, 15, 16], reward: 952.683, convergence: 10000\n",
      "result: [2, 1, 7, 9, 15, 18, 5, 17, 10, 6, 4, 12, 13, 0, 11, 3, 8, 19, 16, 14], reward: 949.190, convergence: 10000\n",
      "result: [2, 1, 17, 9, 4, 18, 5, 8, 10, 0, 3, 19, 13, 12, 11, 6, 14, 7, 15, 16], reward: 955.235, convergence: 10000\n",
      "result: [11, 6, 2, 8, 3, 18, 5, 10, 7, 12, 4, 19, 13, 9, 1, 17, 14, 0, 15, 16], reward: 954.049, convergence: 10000\n",
      "result: [11, 1, 2, 9, 15, 18, 5, 17, 10, 0, 3, 19, 13, 4, 14, 6, 8, 7, 16, 12], reward: 954.348, convergence: 10000\n"
     ]
    }
   ],
   "source": [
    "convergence_threshold = 0.6\n",
    "\n",
    "fpout = open('./experiments/convergence/WTA{}_random_threshold_{}_result.csv'.format(N_WTA, convergence_threshold), 'w')\n",
    "wr = csv.writer(fpout, delimiter=',')\n",
    "wr.writerow(['result', 'reward', 'convergence_iter'])\n",
    "\n",
    "for i_exp in range(N_EXPERIMENTS):\n",
    "    fpout_iter = open('./experiments/plot/WTA{}_random_threshold_{}_experiment{}.csv'.format(N_WTA, convergence_threshold, i_exp), 'w')\n",
    "    fpout_iter.write('i_iter,reward,result\\n')\n",
    "    \n",
    "    wta_1d = WTA_1D_General_GA(config, N_WTA, mutation_method='random')\n",
    "    result, reward, convergence_iter = wta_1d.run(max_iter, convergence_threshold=convergence_threshold, verbose=False, fp=fpout_iter)\n",
    "    \n",
    "    print('result: {}, reward: {:.3f}, convergence: {}'.format(result, reward, convergence_iter))\n",
    "    wr.writerow(['_'.join(map(lambda x: str(x), result)), '{:.3f}'.format(reward), convergence_iter])\n",
    "    \n",
    "    fpout_iter.close()\n",
    "        \n",
    "fpout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: [19, 6, 17, 10, 3, 18, 16, 13, 14, 12, 5, 4, 0, 15, 1, 2, 8, 7, 9, 11], reward: 905.486, convergence: 63\n",
      "result: [11, 6, 17, 9, 15, 18, 5, 13, 10, 12, 3, 4, 14, 0, 1, 2, 8, 7, 19, 16], reward: 946.210, convergence: 4576\n",
      "result: [19, 6, 2, 9, 3, 18, 5, 13, 10, 12, 15, 4, 14, 0, 11, 17, 8, 7, 16, 1], reward: 950.907, convergence: 2743\n",
      "result: [11, 6, 17, 10, 3, 18, 19, 13, 14, 12, 5, 4, 0, 15, 1, 2, 8, 7, 9, 16], reward: 915.643, convergence: 105\n",
      "result: [19, 6, 17, 10, 3, 18, 16, 11, 13, 12, 5, 4, 0, 15, 1, 2, 8, 7, 9, 14], reward: 899.738, convergence: 61\n",
      "result: [19, 6, 17, 10, 3, 18, 16, 11, 13, 12, 5, 4, 0, 15, 1, 2, 8, 7, 9, 14], reward: 899.738, convergence: 73\n",
      "result: [19, 6, 17, 10, 3, 18, 16, 11, 14, 12, 5, 4, 0, 15, 1, 2, 8, 7, 9, 13], reward: 892.151, convergence: 30\n",
      "result: [19, 6, 2, 9, 3, 18, 5, 1, 10, 12, 16, 4, 13, 0, 11, 17, 8, 7, 15, 14], reward: 948.873, convergence: 5212\n",
      "result: [19, 6, 2, 9, 3, 18, 5, 13, 10, 12, 16, 4, 14, 0, 11, 17, 8, 7, 15, 1], reward: 951.179, convergence: 2686\n",
      "result: [19, 6, 17, 10, 3, 18, 5, 1, 14, 12, 16, 4, 0, 15, 11, 2, 8, 7, 9, 13], reward: 911.224, convergence: 102\n"
     ]
    }
   ],
   "source": [
    "convergence_threshold = 0.6\n",
    "\n",
    "fpout = open('./experiments/convergence/WTA{}_dqn_threshold_{}_result.csv'.format(N_WTA, convergence_threshold), 'w')\n",
    "wr = csv.writer(fpout, delimiter=',')\n",
    "wr.writerow(['result', 'reward', 'convergence_iter'])\n",
    "\n",
    "for i_exp in range(N_EXPERIMENTS):\n",
    "    fpout_iter = open('./experiments/plot/WTA{}_dqn_threshold_{}_experiment{}.csv'.format(N_WTA, convergence_threshold, i_exp), 'w')\n",
    "    fpout_iter.write('i_iter,reward,result\\n')\n",
    "    \n",
    "    wta_1d = WTA_1D_General_GA(config, N_WTA, mutation_method='dqn')\n",
    "    result, reward, convergence_iter = wta_1d.run(max_iter, convergence_threshold=convergence_threshold, verbose=False, fp=fpout_iter)\n",
    "    \n",
    "    print('result: {}, reward: {:.3f}, convergence: {}'.format(result, reward, convergence_iter))\n",
    "    wr.writerow(['_'.join(map(lambda x: str(x), result)), '{:.3f}'.format(reward), convergence_iter])\n",
    "    \n",
    "    fpout_iter.close()\n",
    "        \n",
    "fpout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: [19, 0, 5, 11, 4, 2, 13, 1, 10, 15, 3, 12, 14, 18, 17, 6, 8, 9, 7, 16], reward: 895.464, convergence: 42\n",
      "result: [19, 0, 5, 11, 4, 2, 1, 13, 10, 15, 3, 12, 14, 18, 17, 6, 8, 9, 7, 16], reward: 903.258, convergence: 26\n",
      "result: [19, 0, 5, 11, 4, 2, 9, 13, 10, 15, 3, 12, 14, 18, 17, 6, 8, 18, 7, 16], reward: 887.022, convergence: 37\n",
      "result: [19, 0, 5, 11, 17, 2, 13, 1, 10, 15, 3, 12, 14, 8, 4, 6, 9, 18, 7, 16], reward: 889.925, convergence: 47\n",
      "result: [19, 0, 5, 11, 4, 2, 8, 13, 10, 15, 3, 12, 14, 9, 17, 6, 18, 7, 1, 16], reward: 890.960, convergence: 44\n",
      "result: [19, 0, 5, 11, 4, 2, 13, 1, 10, 15, 3, 12, 14, 8, 17, 6, 18, 9, 7, 16], reward: 876.899, convergence: 24\n",
      "result: [19, 0, 5, 11, 18, 2, 1, 13, 10, 15, 3, 12, 14, 8, 7, 6, 18, 9, 17, 16], reward: 878.161, convergence: 24\n",
      "result: [19, 0, 5, 11, 4, 2, 9, 1, 10, 15, 3, 12, 14, 8, 17, 6, 18, 13, 7, 16], reward: 884.122, convergence: 28\n",
      "result: [19, 1, 5, 9, 18, 2, 3, 13, 10, 6, 4, 12, 14, 0, 11, 17, 8, 7, 17, 16], reward: 938.656, convergence: 1740\n",
      "result: [19, 0, 5, 11, 0, 2, 18, 13, 10, 15, 3, 12, 14, 4, 17, 6, 8, 9, 7, 16], reward: 888.880, convergence: 55\n"
     ]
    }
   ],
   "source": [
    "convergence_threshold = 0.6\n",
    "\n",
    "fpout = open('./experiments/convergence/WTA{}_dueling-dqn_threshold_{}_result.csv'.format(N_WTA, convergence_threshold), 'w')\n",
    "wr = csv.writer(fpout, delimiter=',')\n",
    "wr.writerow(['result', 'reward', 'convergence_iter'])\n",
    "\n",
    "for i_exp in range(N_EXPERIMENTS):\n",
    "    fpout_iter = open('./experiments/plot/WTA{}_dueling-dqn_threshold_{}_experiment{}.csv'.format(N_WTA, convergence_threshold, i_exp), 'w')\n",
    "    fpout_iter.write('i_iter,reward,result\\n')\n",
    "    \n",
    "    wta_1d = WTA_1D_General_GA(config, N_WTA, mutation_method='dueling_dqn')\n",
    "    result, reward, convergence_iter = wta_1d.run(max_iter, convergence_threshold=convergence_threshold, verbose=False, fp=fpout_iter)\n",
    "    \n",
    "    print('result: {}, reward: {:.3f}, convergence: {}'.format(result, reward, convergence_iter))\n",
    "    wr.writerow(['_'.join(map(lambda x: str(x), result)), '{:.3f}'.format(reward), convergence_iter])\n",
    "    \n",
    "    fpout_iter.close()\n",
    "        \n",
    "fpout.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convergence threshold 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: [2, 15, 17, 9, 1, 10, 3, 13, 7, 12, 4, 18, 14, 0, 11, 6, 8, 5, 19, 16], reward: 949.812, convergence: 10000\n",
      "result: [11, 1, 17, 9, 0, 2, 5, 18, 10, 12, 3, 19, 13, 4, 14, 6, 8, 7, 15, 16], reward: 954.166, convergence: 10000\n",
      "result: [2, 8, 17, 9, 1, 18, 5, 10, 7, 12, 3, 19, 13, 4, 11, 6, 14, 0, 15, 16], reward: 960.188, convergence: 10000\n",
      "result: [19, 1, 5, 9, 15, 10, 3, 8, 7, 12, 17, 18, 13, 4, 11, 6, 14, 0, 16, 2], reward: 954.401, convergence: 10000\n",
      "result: [15, 8, 7, 9, 1, 2, 5, 17, 10, 12, 3, 18, 13, 4, 11, 6, 14, 0, 19, 16], reward: 951.906, convergence: 10000\n",
      "result: [18, 8, 6, 9, 1, 3, 2, 10, 4, 12, 17, 19, 5, 0, 11, 13, 14, 7, 15, 16], reward: 939.936, convergence: 10000\n",
      "result: [2, 1, 6, 9, 3, 18, 5, 17, 10, 12, 0, 19, 13, 4, 11, 14, 8, 7, 15, 16], reward: 952.941, convergence: 10000\n",
      "result: [11, 1, 5, 9, 3, 10, 19, 17, 7, 6, 18, 12, 13, 4, 14, 15, 8, 0, 16, 2], reward: 946.463, convergence: 10000\n",
      "result: [2, 6, 3, 9, 1, 18, 5, 17, 7, 19, 10, 4, 13, 12, 11, 14, 8, 0, 15, 16], reward: 942.805, convergence: 10000\n",
      "result: [18, 1, 2, 9, 15, 10, 3, 13, 7, 12, 17, 4, 19, 0, 11, 6, 8, 5, 16, 14], reward: 945.201, convergence: 10000\n"
     ]
    }
   ],
   "source": [
    "convergence_threshold = 0.7\n",
    "\n",
    "fpout = open('./experiments/convergence/WTA{}_random_threshold_{}_result.csv'.format(N_WTA, convergence_threshold), 'w')\n",
    "wr = csv.writer(fpout, delimiter=',')\n",
    "wr.writerow(['result', 'reward', 'convergence_iter'])\n",
    "\n",
    "for i_exp in range(N_EXPERIMENTS):\n",
    "    fpout_iter = open('./experiments/plot/WTA{}_random_threshold_{}_experiment{}.csv'.format(N_WTA, convergence_threshold, i_exp), 'w')\n",
    "    fpout_iter.write('i_iter,reward,result\\n')\n",
    "    \n",
    "    wta_1d = WTA_1D_General_GA(config, N_WTA, mutation_method='random')\n",
    "    result, reward, convergence_iter = wta_1d.run(max_iter, convergence_threshold=convergence_threshold, verbose=False, fp=fpout_iter)\n",
    "    \n",
    "    print('result: {}, reward: {:.3f}, convergence: {}'.format(result, reward, convergence_iter))\n",
    "    wr.writerow(['_'.join(map(lambda x: str(x), result)), '{:.3f}'.format(reward), convergence_iter])\n",
    "    \n",
    "    fpout_iter.close()\n",
    "        \n",
    "fpout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: [19, 6, 17, 10, 3, 18, 16, 13, 14, 12, 5, 4, 0, 15, 1, 2, 8, 7, 9, 11], reward: 905.486, convergence: 73\n",
      "result: [19, 6, 17, 10, 3, 18, 5, 11, 13, 12, 16, 4, 0, 15, 1, 2, 8, 7, 9, 14], reward: 911.682, convergence: 131\n",
      "result: [19, 6, 2, 9, 16, 18, 5, 13, 10, 12, 3, 4, 14, 0, 11, 17, 8, 7, 15, 1], reward: 952.806, convergence: 8166\n",
      "result: [13, 6, 17, 10, 3, 18, 5, 11, 14, 12, 16, 4, 0, 15, 1, 2, 8, 7, 9, 19], reward: 896.559, convergence: 57\n",
      "result: [19, 6, 2, 9, 3, 18, 5, 13, 10, 12, 16, 4, 14, 0, 11, 17, 8, 7, 15, 1], reward: 951.179, convergence: 6888\n",
      "result: [11, 6, 2, 9, 16, 18, 5, 1, 10, 0, 3, 4, 13, 15, 14, 17, 8, 7, 19, 12], reward: 943.463, convergence: 10000\n",
      "result: [11, 6, 17, 9, 15, 18, 5, 13, 10, 12, 3, 4, 14, 0, 1, 2, 8, 7, 19, 16], reward: 946.210, convergence: 5070\n",
      "result: [19, 6, 2, 9, 3, 18, 5, 13, 10, 12, 16, 4, 14, 0, 11, 17, 8, 7, 15, 1], reward: 951.179, convergence: 4096\n",
      "result: [19, 6, 17, 10, 3, 18, 16, 13, 14, 12, 5, 4, 0, 15, 1, 2, 8, 7, 9, 11], reward: 905.486, convergence: 94\n",
      "result: [19, 6, 17, 10, 3, 18, 16, 11, 14, 12, 5, 4, 13, 15, 1, 2, 8, 7, 9, 0], reward: 903.932, convergence: 38\n"
     ]
    }
   ],
   "source": [
    "convergence_threshold = 0.7\n",
    "\n",
    "fpout = open('./experiments/convergence/WTA{}_dqn_threshold_{}_result.csv'.format(N_WTA, convergence_threshold), 'w')\n",
    "wr = csv.writer(fpout, delimiter=',')\n",
    "wr.writerow(['result', 'reward', 'convergence_iter'])\n",
    "\n",
    "for i_exp in range(N_EXPERIMENTS):\n",
    "    fpout_iter = open('./experiments/plot/WTA{}_dqn_threshold_{}_experiment{}.csv'.format(N_WTA, convergence_threshold, i_exp), 'w')\n",
    "    fpout_iter.write('i_iter,reward,result\\n')\n",
    "    \n",
    "    wta_1d = WTA_1D_General_GA(config, N_WTA, mutation_method='dqn')\n",
    "    result, reward, convergence_iter = wta_1d.run(max_iter, convergence_threshold=convergence_threshold, verbose=False, fp=fpout_iter)\n",
    "    \n",
    "    print('result: {}, reward: {:.3f}, convergence: {}'.format(result, reward, convergence_iter))\n",
    "    wr.writerow(['_'.join(map(lambda x: str(x), result)), '{:.3f}'.format(reward), convergence_iter])\n",
    "    \n",
    "    fpout_iter.close()\n",
    "        \n",
    "fpout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: [19, 1, 5, 18, 17, 2, 3, 13, 10, 0, 4, 12, 14, 9, 11, 6, 8, 7, 16, 17], reward: 937.026, convergence: 1761\n",
      "result: [19, 7, 5, 18, 1, 2, 3, 13, 10, 6, 4, 12, 14, 9, 11, 17, 8, 0, 15, 16], reward: 949.295, convergence: 4440\n",
      "result: [19, 0, 5, 11, 4, 2, 1, 13, 10, 15, 3, 12, 14, 8, 17, 6, 18, 9, 7, 16], reward: 884.693, convergence: 37\n",
      "result: [19, 0, 5, 11, 4, 2, 9, 18, 10, 0, 3, 12, 14, 7, 17, 6, 8, 13, 15, 16], reward: 891.980, convergence: 51\n",
      "result: [19, 1, 5, 9, 18, 2, 3, 13, 10, 6, 4, 12, 14, 0, 11, 17, 8, 7, 16, 17], reward: 938.690, convergence: 2314\n",
      "result: [19, 0, 5, 11, 4, 2, 7, 13, 10, 15, 3, 12, 14, 18, 17, 6, 8, 9, 7, 16], reward: 888.723, convergence: 42\n",
      "result: [19, 1, 5, 9, 18, 2, 3, 13, 10, 6, 4, 12, 14, 0, 11, 17, 8, 7, 15, 16], reward: 952.873, convergence: 6839\n",
      "result: [19, 0, 5, 11, 4, 2, 13, 1, 10, 2, 3, 12, 14, 18, 17, 6, 8, 9, 7, 16], reward: 886.069, convergence: 43\n",
      "result: [19, 0, 5, 9, 4, 2, 13, 8, 10, 15, 3, 12, 14, 1, 17, 6, 18, 11, 7, 16], reward: 889.510, convergence: 24\n",
      "result: [19, 1, 5, 9, 18, 2, 3, 13, 10, 0, 17, 12, 14, 4, 11, 6, 8, 7, 15, 16], reward: 953.059, convergence: 8014\n"
     ]
    }
   ],
   "source": [
    "convergence_threshold = 0.7\n",
    "\n",
    "fpout = open('./experiments/convergence/WTA{}_dueling-dqn_threshold_{}_result.csv'.format(N_WTA, convergence_threshold), 'w')\n",
    "wr = csv.writer(fpout, delimiter=',')\n",
    "wr.writerow(['result', 'reward', 'convergence_iter'])\n",
    "\n",
    "for i_exp in range(N_EXPERIMENTS):\n",
    "    fpout_iter = open('./experiments/plot/WTA{}_dueling-dqn_threshold_{}_experiment{}.csv'.format(N_WTA, convergence_threshold, i_exp), 'w')\n",
    "    fpout_iter.write('i_iter,reward,result\\n')\n",
    "    \n",
    "    wta_1d = WTA_1D_General_GA(config, N_WTA, mutation_method='dueling_dqn')\n",
    "    result, reward, convergence_iter = wta_1d.run(max_iter, convergence_threshold=convergence_threshold, verbose=False, fp=fpout_iter)\n",
    "    \n",
    "    print('result: {}, reward: {:.3f}, convergence: {}'.format(result, reward, convergence_iter))\n",
    "    wr.writerow(['_'.join(map(lambda x: str(x), result)), '{:.3f}'.format(reward), convergence_iter])\n",
    "    \n",
    "    fpout_iter.close()\n",
    "        \n",
    "fpout.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convergence threshold 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: [15, 1, 17, 9, 3, 10, 5, 8, 7, 12, 4, 19, 13, 18, 11, 6, 14, 0, 16, 2], reward: 952.131, convergence: 10000\n",
      "result: [10, 1, 5, 9, 15, 2, 3, 17, 7, 12, 18, 19, 13, 4, 11, 6, 8, 0, 16, 14], reward: 949.276, convergence: 10000\n",
      "result: [2, 1, 6, 9, 17, 18, 5, 10, 7, 12, 4, 19, 13, 0, 11, 3, 8, 14, 15, 16], reward: 954.938, convergence: 10000\n",
      "result: [2, 8, 9, 3, 1, 18, 5, 17, 10, 12, 4, 19, 13, 0, 11, 6, 14, 7, 15, 16], reward: 952.158, convergence: 10000\n",
      "result: [6, 1, 7, 9, 18, 2, 3, 13, 10, 12, 17, 19, 14, 4, 11, 0, 8, 5, 15, 16], reward: 948.849, convergence: 10000\n",
      "result: [2, 1, 17, 9, 15, 18, 5, 10, 7, 12, 3, 19, 13, 4, 11, 6, 8, 0, 14, 16], reward: 957.527, convergence: 10000\n",
      "result: [19, 8, 5, 9, 1, 18, 2, 17, 10, 12, 3, 4, 13, 0, 11, 6, 14, 7, 15, 16], reward: 953.311, convergence: 10000\n",
      "result: [2, 1, 11, 9, 15, 10, 3, 18, 7, 12, 17, 19, 13, 0, 14, 6, 8, 5, 16, 4], reward: 948.844, convergence: 10000\n",
      "result: [11, 1, 17, 9, 15, 18, 2, 10, 7, 0, 3, 19, 13, 4, 14, 6, 8, 5, 16, 12], reward: 951.425, convergence: 10000\n",
      "result: [15, 1, 2, 9, 3, 18, 5, 17, 10, 6, 7, 19, 13, 4, 11, 14, 8, 0, 16, 12], reward: 953.242, convergence: 10000\n"
     ]
    }
   ],
   "source": [
    "convergence_threshold = 0.8\n",
    "\n",
    "fpout = open('./experiments/convergence/WTA{}_random_threshold_{}_result.csv'.format(N_WTA, convergence_threshold), 'w')\n",
    "wr = csv.writer(fpout, delimiter=',')\n",
    "wr.writerow(['result', 'reward', 'convergence_iter'])\n",
    "\n",
    "for i_exp in range(N_EXPERIMENTS):\n",
    "    fpout_iter = open('./experiments/plot/WTA{}_random_threshold_{}_experiment{}.csv'.format(N_WTA, convergence_threshold, i_exp), 'w')\n",
    "    fpout_iter.write('i_iter,reward,result\\n')\n",
    "    \n",
    "    wta_1d = WTA_1D_General_GA(config, N_WTA, mutation_method='random')\n",
    "    result, reward, convergence_iter = wta_1d.run(max_iter, convergence_threshold=convergence_threshold, verbose=False, fp=fpout_iter)\n",
    "    \n",
    "    print('result: {}, reward: {:.3f}, convergence: {}'.format(result, reward, convergence_iter))\n",
    "    wr.writerow(['_'.join(map(lambda x: str(x), result)), '{:.3f}'.format(reward), convergence_iter])\n",
    "    \n",
    "    fpout_iter.close()\n",
    "        \n",
    "fpout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: [19, 6, 2, 9, 3, 18, 5, 13, 10, 12, 15, 4, 14, 0, 11, 17, 8, 7, 16, 1], reward: 950.907, convergence: 5828\n",
      "result: [19, 6, 17, 10, 3, 18, 16, 11, 14, 12, 5, 4, 0, 15, 1, 2, 8, 7, 9, 13], reward: 892.151, convergence: 69\n",
      "result: [19, 6, 17, 10, 3, 18, 16, 13, 14, 12, 5, 4, 0, 15, 1, 2, 8, 7, 9, 11], reward: 905.486, convergence: 103\n",
      "result: [19, 6, 17, 10, 3, 18, 16, 11, 14, 12, 5, 4, 13, 15, 1, 2, 8, 7, 9, 0], reward: 903.932, convergence: 50\n",
      "result: [19, 6, 17, 10, 3, 18, 16, 1, 13, 12, 5, 4, 0, 15, 11, 2, 8, 7, 9, 14], reward: 906.868, convergence: 114\n",
      "result: [19, 6, 2, 9, 3, 18, 5, 13, 10, 12, 16, 4, 14, 0, 11, 17, 8, 7, 15, 1], reward: 951.179, convergence: 10000\n",
      "result: [19, 6, 2, 9, 3, 18, 5, 1, 10, 12, 14, 4, 13, 0, 11, 17, 8, 7, 15, 16], reward: 950.499, convergence: 7054\n",
      "result: [19, 6, 2, 9, 16, 18, 5, 13, 10, 12, 3, 4, 14, 0, 11, 17, 8, 7, 15, 1], reward: 952.806, convergence: 6184\n",
      "result: [11, 6, 17, 9, 15, 18, 5, 13, 10, 12, 3, 4, 14, 0, 1, 2, 8, 7, 19, 16], reward: 946.210, convergence: 4511\n",
      "result: [19, 6, 2, 9, 16, 18, 5, 13, 10, 12, 3, 4, 14, 0, 11, 17, 8, 7, 15, 1], reward: 952.806, convergence: 6476\n"
     ]
    }
   ],
   "source": [
    "convergence_threshold = 0.8\n",
    "\n",
    "fpout = open('./experiments/convergence/WTA{}_dqn_threshold_{}_result.csv'.format(N_WTA, convergence_threshold), 'w')\n",
    "wr = csv.writer(fpout, delimiter=',')\n",
    "wr.writerow(['result', 'reward', 'convergence_iter'])\n",
    "\n",
    "for i_exp in range(N_EXPERIMENTS):\n",
    "    fpout_iter = open('./experiments/plot/WTA{}_dqn_threshold_{}_experiment{}.csv'.format(N_WTA, convergence_threshold, i_exp), 'w')\n",
    "    fpout_iter.write('i_iter,reward,result\\n')\n",
    "    \n",
    "    wta_1d = WTA_1D_General_GA(config, N_WTA, mutation_method='dqn')\n",
    "    result, reward, convergence_iter = wta_1d.run(max_iter, convergence_threshold=convergence_threshold, verbose=False, fp=fpout_iter)\n",
    "    \n",
    "    print('result: {}, reward: {:.3f}, convergence: {}'.format(result, reward, convergence_iter))\n",
    "    wr.writerow(['_'.join(map(lambda x: str(x), result)), '{:.3f}'.format(reward), convergence_iter])\n",
    "    \n",
    "    fpout_iter.close()\n",
    "        \n",
    "fpout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: [19, 7, 5, 9, 1, 2, 3, 13, 10, 0, 17, 12, 18, 4, 11, 6, 8, 14, 15, 16], reward: 949.660, convergence: 6571\n",
      "result: [19, 1, 5, 9, 18, 2, 3, 13, 10, 6, 4, 12, 14, 0, 11, 17, 8, 7, 15, 16], reward: 952.873, convergence: 9539\n",
      "result: [19, 0, 5, 11, 4, 2, 9, 1, 10, 15, 3, 12, 14, 8, 17, 6, 18, 13, 7, 16], reward: 884.122, convergence: 35\n",
      "result: [19, 0, 5, 11, 4, 2, 18, 1, 10, 15, 3, 12, 14, 8, 17, 6, 9, 13, 7, 16], reward: 886.971, convergence: 36\n",
      "result: [19, 1, 5, 9, 18, 2, 3, 13, 10, 6, 4, 12, 14, 0, 11, 17, 8, 7, 15, 16], reward: 952.873, convergence: 9875\n",
      "result: [19, 1, 5, 9, 18, 2, 3, 13, 10, 6, 4, 12, 14, 0, 11, 17, 8, 7, 16, 17], reward: 938.690, convergence: 4033\n",
      "result: [19, 1, 5, 9, 18, 2, 3, 13, 10, 0, 17, 12, 14, 4, 11, 6, 8, 7, 15, 16], reward: 953.059, convergence: 10000\n",
      "result: [19, 1, 5, 9, 15, 2, 3, 13, 10, 6, 18, 12, 14, 4, 11, 17, 8, 0, 7, 16], reward: 950.667, convergence: 10000\n",
      "result: [19, 1, 5, 8, 18, 2, 3, 13, 10, 6, 4, 12, 14, 0, 11, 17, 9, 7, 15, 16], reward: 948.467, convergence: 6236\n",
      "result: [19, 1, 5, 9, 18, 2, 3, 13, 10, 0, 17, 12, 14, 4, 11, 6, 8, 7, 15, 16], reward: 953.059, convergence: 10000\n"
     ]
    }
   ],
   "source": [
    "convergence_threshold = 0.8\n",
    "\n",
    "fpout = open('./experiments/convergence/WTA{}_dueling-dqn_threshold_{}_result.csv'.format(N_WTA, convergence_threshold), 'w')\n",
    "wr = csv.writer(fpout, delimiter=',')\n",
    "wr.writerow(['result', 'reward', 'convergence_iter'])\n",
    "\n",
    "for i_exp in range(N_EXPERIMENTS):\n",
    "    fpout_iter = open('./experiments/plot/WTA{}_dueling-dqn_threshold_{}_experiment{}.csv'.format(N_WTA, convergence_threshold, i_exp), 'w')\n",
    "    fpout_iter.write('i_iter,reward,result\\n')\n",
    "    \n",
    "    wta_1d = WTA_1D_General_GA(config, N_WTA, mutation_method='dueling_dqn')\n",
    "    result, reward, convergence_iter = wta_1d.run(max_iter, convergence_threshold=convergence_threshold, verbose=False, fp=fpout_iter)\n",
    "    \n",
    "    print('result: {}, reward: {:.3f}, convergence: {}'.format(result, reward, convergence_iter))\n",
    "    wr.writerow(['_'.join(map(lambda x: str(x), result)), '{:.3f}'.format(reward), convergence_iter])\n",
    "    \n",
    "    fpout_iter.close()\n",
    "        \n",
    "fpout.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convergence threshold 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convergence threshold 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_reward(filename_list, dataname_list, title=''):\n",
    "    plt.figure(figsize=(20,10))\n",
    "    for idx, filename in enumerate(filename_list):\n",
    "        df = pd.read_csv(filename)\n",
    "        plt.plot(df.i_iter, df.reward, label=dataname_list[idx])\n",
    "    plt.legend()\n",
    "    plt.ylabel('reward')\n",
    "    plt.xlabel('iteration')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Threshold 50% - reward: 951.37 (3.761), convergence_iter: 10000.00 (0.000)\n",
      "Random Threshold 60% - reward: 951.50 (2.496), convergence_iter: 10000.00 (0.000)\n",
      "Random Threshold 70% - reward: 949.78 (6.155), convergence_iter: 10000.00 (0.000)\n",
      "Random Threshold 80% - reward: 952.17 (2.786), convergence_iter: 10000.00 (0.000)\n"
     ]
    }
   ],
   "source": [
    "df_threshold_50 = pd.read_csv('./experiments/convergence/WTA3_random_threshold_0.5_result.csv')\n",
    "df_threshold_60 = pd.read_csv('./experiments/convergence/WTA3_random_threshold_0.6_result.csv')\n",
    "df_threshold_70 = pd.read_csv('./experiments/convergence/WTA3_random_threshold_0.7_result.csv')\n",
    "df_threshold_80 = pd.read_csv('./experiments/convergence/WTA3_random_threshold_0.8_result.csv')\n",
    "\n",
    "print('Random Threshold 50% - reward: {:.2f} ({:.3f}), convergence_iter: {:.2f} ({:.3f})'.format(df_threshold_50['reward'].mean(), df_threshold_50['reward'].std(), df_threshold_50['convergence_iter'].mean(), df_threshold_50['convergence_iter'].std()))\n",
    "print('Random Threshold 60% - reward: {:.2f} ({:.3f}), convergence_iter: {:.2f} ({:.3f})'.format(df_threshold_60['reward'].mean(), df_threshold_60['reward'].std(), df_threshold_60['convergence_iter'].mean(), df_threshold_60['convergence_iter'].std()))\n",
    "print('Random Threshold 70% - reward: {:.2f} ({:.3f}), convergence_iter: {:.2f} ({:.3f})'.format(df_threshold_70['reward'].mean(), df_threshold_70['reward'].std(), df_threshold_70['convergence_iter'].mean(), df_threshold_70['convergence_iter'].std()))\n",
    "print('Random Threshold 80% - reward: {:.2f} ({:.3f}), convergence_iter: {:.2f} ({:.3f})'.format(df_threshold_80['reward'].mean(), df_threshold_80['reward'].std(), df_threshold_80['convergence_iter'].mean(), df_threshold_80['convergence_iter'].std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DQN Threshold 50% - reward: 919.54 (22.314), convergence_iter: 1179.00 (1495.911)\n",
      "DQN Threshold 60% - reward: 922.11 (24.282), convergence_iter: 1565.10 (2065.143)\n",
      "DQN Threshold 70% - reward: 926.80 (23.791), convergence_iter: 3461.30 (3899.291)\n",
      "DQN Threshold 80% - reward: 931.28 (25.474), convergence_iter: 4038.90 (3669.057)\n",
      "DQN Threshold 100% - reward: 913.26 (28.217), convergence_iter: 1882.50 (2494.006)\n"
     ]
    }
   ],
   "source": [
    "df_threshold_50 = pd.read_csv('./experiments/convergence/WTA3_dqn_threshold_0.5_result.csv')\n",
    "df_threshold_60 = pd.read_csv('./experiments/convergence/WTA3_dqn_threshold_0.6_result.csv')\n",
    "df_threshold_70 = pd.read_csv('./experiments/convergence/WTA3_dqn_threshold_0.7_result.csv')\n",
    "df_threshold_80 = pd.read_csv('./experiments/convergence/WTA3_dqn_threshold_0.8_result.csv')\n",
    "df_threshold_100 = pd.read_csv('./experiments/WTA3/dqn_mutation.csv')\n",
    "\n",
    "print('DQN Threshold 50% - reward: {:.2f} ({:.3f}), convergence_iter: {:.2f} ({:.3f})'.format(df_threshold_50['reward'].mean(), df_threshold_50['reward'].std(), df_threshold_50['convergence_iter'].mean(), df_threshold_50['convergence_iter'].std()))\n",
    "print('DQN Threshold 60% - reward: {:.2f} ({:.3f}), convergence_iter: {:.2f} ({:.3f})'.format(df_threshold_60['reward'].mean(), df_threshold_60['reward'].std(), df_threshold_60['convergence_iter'].mean(), df_threshold_60['convergence_iter'].std()))\n",
    "print('DQN Threshold 70% - reward: {:.2f} ({:.3f}), convergence_iter: {:.2f} ({:.3f})'.format(df_threshold_70['reward'].mean(), df_threshold_70['reward'].std(), df_threshold_70['convergence_iter'].mean(), df_threshold_70['convergence_iter'].std()))\n",
    "print('DQN Threshold 80% - reward: {:.2f} ({:.3f}), convergence_iter: {:.2f} ({:.3f})'.format(df_threshold_80['reward'].mean(), df_threshold_80['reward'].std(), df_threshold_80['convergence_iter'].mean(), df_threshold_80['convergence_iter'].std()))\n",
    "print('DQN Threshold 100% - reward: {:.2f} ({:.3f}), convergence_iter: {:.2f} ({:.3f})'.format(df_threshold_100['reward'].mean(), df_threshold_100['reward'].std(), df_threshold_100['convergence_iter'].mean(), df_threshold_100['convergence_iter'].std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dueling DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dueling DQN Threshold 50% - reward: 921.68 (29.071), convergence_iter: 1818.40 (2652.644)\n",
      "Dueling DQN Threshold 60% - reward: 893.33 (17.699), convergence_iter: 206.70 (538.853)\n",
      "Dueling DQN Threshold 70% - reward: 917.19 (31.061), convergence_iter: 2356.50 (3048.546)\n",
      "Dueling DQN Threshold 80% - reward: 937.04 (27.487), convergence_iter: 6632.50 (4040.640)\n",
      "Dueling DQN Threshold 100% - reward: 907.78 (36.415), convergence_iter: 2191.50 (2558.097)\n"
     ]
    }
   ],
   "source": [
    "df_threshold_50 = pd.read_csv('./experiments/convergence/WTA3_dueling-dqn_threshold_0.5_result.csv')\n",
    "df_threshold_60 = pd.read_csv('./experiments/convergence/WTA3_dueling-dqn_threshold_0.6_result.csv')\n",
    "df_threshold_70 = pd.read_csv('./experiments/convergence/WTA3_dueling-dqn_threshold_0.7_result.csv')\n",
    "df_threshold_80 = pd.read_csv('./experiments/convergence/WTA3_dueling-dqn_threshold_0.8_result.csv')\n",
    "df_threshold_100 = pd.read_csv('./experiments/WTA3/dueling_dqn_mutation.csv')\n",
    "\n",
    "print('Dueling DQN Threshold 50% - reward: {:.2f} ({:.3f}), convergence_iter: {:.2f} ({:.3f})'.format(df_threshold_50['reward'].mean(), df_threshold_50['reward'].std(), df_threshold_50['convergence_iter'].mean(), df_threshold_50['convergence_iter'].std()))\n",
    "print('Dueling DQN Threshold 60% - reward: {:.2f} ({:.3f}), convergence_iter: {:.2f} ({:.3f})'.format(df_threshold_60['reward'].mean(), df_threshold_60['reward'].std(), df_threshold_60['convergence_iter'].mean(), df_threshold_60['convergence_iter'].std()))\n",
    "print('Dueling DQN Threshold 70% - reward: {:.2f} ({:.3f}), convergence_iter: {:.2f} ({:.3f})'.format(df_threshold_70['reward'].mean(), df_threshold_70['reward'].std(), df_threshold_70['convergence_iter'].mean(), df_threshold_70['convergence_iter'].std()))\n",
    "print('Dueling DQN Threshold 80% - reward: {:.2f} ({:.3f}), convergence_iter: {:.2f} ({:.3f})'.format(df_threshold_80['reward'].mean(), df_threshold_80['reward'].std(), df_threshold_80['convergence_iter'].mean(), df_threshold_80['convergence_iter'].std()))\n",
    "print('Dueling DQN Threshold 100% - reward: {:.2f} ({:.3f}), convergence_iter: {:.2f} ({:.3f})'.format(df_threshold_100['reward'].mean(), df_threshold_100['reward'].std(), df_threshold_100['convergence_iter'].mean(), df_threshold_100['convergence_iter'].std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
