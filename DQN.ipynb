{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iKFM3HVilaMB"
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FFdaczjmlcEK"
   },
   "outputs": [],
   "source": [
    "from gym import error, spaces, utils\n",
    "from gym.utils import seeding\n",
    "\n",
    "# Create a custom environment \n",
    "class WTAEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['console']}\n",
    "\n",
    "    def __init__(self, n, m, lower_val, upper_val, prob, device):\n",
    "        ''' \n",
    "        n - number of targets\n",
    "        m - number of weapons\n",
    "        lower_val/upper_val - lower/upper range to randomly generate target values from\n",
    "        prob - m x n array where prob[i, j] = probability of weapon i killing target j\n",
    "        ''' \n",
    "        super(WTAEnv, self).__init__()\n",
    "        \n",
    "        self.n = n\n",
    "        self.m = m\n",
    "        self.device = device\n",
    "        \n",
    "        self.target_values = np.random.uniform(lower_val, upper_val, self.n) \n",
    "        self.prob = prob\n",
    "        # q = probability array of survival\n",
    "        self.q = 1 - self.prob\n",
    "        \n",
    "        self.reset()\n",
    "\n",
    "        # Current expected value of the assignment\n",
    "        self.value = self.assignment_value()\n",
    "        \n",
    "        # The action space - a number 0 <= i < m * n, where\n",
    "        # (weapon = i // n, target = i % n)\n",
    "        # Assigns weapon to target (one target per weapon)\n",
    "        self.action_space = spaces.MultiDiscrete([self.m * self.n])\n",
    "        \n",
    "    def decode_action(self, action):\n",
    "        '''\n",
    "        Given an action, return the weapon and target associated with\n",
    "        that action.\n",
    "        '''\n",
    "        return action // self.n, action % self.n\n",
    "        \n",
    "    def get_onehot_assignments(self):\n",
    "        '''\n",
    "        Get a one-hot encoded representation of the assignments.\n",
    "        This is used only because this representation is convenient and\n",
    "        fast for computing the assignment value, since we can use\n",
    "        vectorization and not use for loops. Not sure how much this\n",
    "        actually helps though.\n",
    "        '''\n",
    "        onehot = np.zeros((self.m, self.n))\n",
    "        onehot[np.arange(onehot.shape[0]), self.assignment] = 1\n",
    "        return onehot\n",
    " \n",
    "    def assignment_value(self):\n",
    "        '''\n",
    "        Compute the expected value of our assignment.\n",
    "        E = Sum over targets i [P(target i killed) * Value(i)]\n",
    "        where P(target i killed) = 1 - P(i survives)\n",
    "        where P(i surves) = 1 - Product over weapons j [P(i survives j) = q[i, j]]\n",
    "        '''\n",
    "        pkill = 1 - np.prod(self.q ** self.assignment_onehot, axis=0)\n",
    "        expected_value = np.dot(pkill, self.target_values)\n",
    "        return expected_value\n",
    "        \n",
    "    def step(self, action):\n",
    "        '''Perform action on the current state'''\n",
    "        weapon, target = self.decode_action(action[0])\n",
    "        if weapon < 0 or weapon >= self.m or target < 0 or target >= self.n:\n",
    "            raise ValueError(\"Received invalid action={} which is not part of the action space\".format(action))\n",
    "        # Update assignments\n",
    "        old_target = self.assignment[weapon]\n",
    "        self.assignment[weapon] = target\n",
    "        self.assignment_onehot[weapon, old_target] = 0\n",
    "        self.assignment_onehot[weapon, target] = 1\n",
    "\n",
    "        # Reward is change in assignment value\n",
    "        new_value = self.assignment_value()\n",
    "        reward = new_value - self.value\n",
    "        self.value = new_value\n",
    "\n",
    "        # There is no stopping condition other than the max number of iterations\n",
    "        done = False\n",
    "\n",
    "        return (self.get_state(), reward, done, {})\n",
    "\n",
    "    def get_state(self):\n",
    "        '''\n",
    "        Our state is a size m + n array.\n",
    "        state[:m] is self.assignments\n",
    "        state[m:] is self.target_values\n",
    "        '''\n",
    "        state = np.concatenate([self.assignment, self.target_values])\n",
    "        return torch.tensor(state, device=self.device)\n",
    "\n",
    "    def reset(self):\n",
    "        '''\n",
    "        Important: the observation must be a numpy array\n",
    "        :return: (np.array) \n",
    "        '''\n",
    "        self.assignment = self.generate_initial_assignment()\n",
    "        self.assignment_onehot = self.get_onehot_assignments()\n",
    "        return self.get_state()\n",
    "    \n",
    "    def generate_initial_assignment(self):\n",
    "        '''   \n",
    "        Randomly assign weapons to targets\n",
    "        ''' \n",
    "        assignment = np.random.randint(self.n, size=self.m)\n",
    "        return assignment\n",
    "\n",
    "    def render(self, mode='human', close=False):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wG4OUdZ2lfat"
   },
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "class ReplayMemory(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Saves a transition.\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "brm37nR4lptv"
   },
   "outputs": [],
   "source": [
    "steps_done = 0\n",
    "\n",
    "def is_possible(state, weapon, target):\n",
    "    '''\n",
    "    We don't want to assign a weapon to the target if it is already assigned\n",
    "    to the target, since this does not change the state at all.\n",
    "    '''\n",
    "    curr_target = state[weapon].item()\n",
    "    return curr_target != target \n",
    "\n",
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        ## Exploit\n",
    "        with torch.no_grad():\n",
    "            policy_net.eval()\n",
    "            state_batch = torch.unsqueeze(state, 1).transpose(0, 1).float()\n",
    "            largest = torch.sort(policy_net(state_batch), descending=True, dim=1)[1]\n",
    "            policy_net.train()\n",
    "            \n",
    "            # Try until we get a valid action\n",
    "            for i in largest[0]:\n",
    "                weapon = i / n\n",
    "                target = i % n\n",
    "                \n",
    "                if is_possible(state, weapon.item(), target.item()):\n",
    "                    return torch.tensor([i], device=device)\n",
    "                \n",
    "            # This should never happen\n",
    "            raise ValueError('Invalid state: no possible action')\n",
    "    else:\n",
    "        ## Explore\n",
    "        weapon = np.random.randint(m)\n",
    "        curr_target = state[weapon].item()\n",
    "        target = np.random.randint(n)\n",
    "        while target == curr_target:\n",
    "            target = np.random.randint(n)\n",
    "        \n",
    "        action = weapon * n + target\n",
    "        return torch.tensor([action], device=device, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dXAtvLthltku"
   },
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "        \n",
    "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "    # detailed explanation). This converts batch-array of Transitions\n",
    "    # to Transition of batch-arrays.\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    # (a final state would've been the one after which simulation ended)\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
    "    non_final_next_states = torch.stack([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "        \n",
    "    state_batch = torch.stack(batch.state)\n",
    "    action_batch = torch.stack(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken. These are the actions which would've been taken\n",
    "    # for each batch state according to policy_net\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    # Expected values of actions for non_final_next_states are computed based\n",
    "    # on the \"older\" target_net; selecting their best reward with max(1)[0].\n",
    "    # This is merged based on the mask, such that we'll have either the expected\n",
    "    # state value or 0 in case the state was final.\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n",
    "\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    # Compute Huber loss\n",
    "    loss = F.smooth_l1_loss(state_action_values.double(), expected_state_action_values.unsqueeze(1).double())\n",
    "    value_loss = loss.item()\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()\n",
    "    \n",
    "    return value_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RujMbIuTlmZK"
   },
   "outputs": [],
   "source": [
    "'''Take in n by m matrix, convert it to 1D feature vector '''\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, n, m, embedding_size=8):\n",
    "        super(DQN, self).__init__()\n",
    "        # The assignment becomes embedded, so it has size m * embedding_size\n",
    "        # when flattened\n",
    "        # The n comes from the values attached\n",
    "        self.assignment_size = m * embedding_size\n",
    "        self.input_size = self.assignment_size + n\n",
    "        self.output_size = m * n\n",
    "        self.n = n\n",
    "        self.m = m\n",
    "        \n",
    "        units = 50\n",
    "\n",
    "        self.embedding_size = embedding_size\n",
    "        # Embed the targets, since the actual numerical value of the\n",
    "        # targets don't mean anything\n",
    "        # Another idea: skip the middleman and replace the targets\n",
    "        # with the target values\n",
    "        self.embedding = nn.Embedding(n, self.embedding_size)\n",
    "        self.lin1 = nn.Linear(self.input_size, units)\n",
    "        self.drop1 = nn.Dropout(0.2)\n",
    "        self.lin2 = nn.Linear(units, self.output_size)\n",
    "        self.drop2 = nn.Dropout(0.2)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, state):\n",
    "        assignment = state[:, :self.m].long()\n",
    "        assignment = self.embedding(assignment)\n",
    "        \n",
    "        values = state[:, self.m:].float()\n",
    "                \n",
    "        # Flatten the assignment embedding\n",
    "        assignment = assignment.view(-1, self.assignment_size).float() \n",
    "        \n",
    "        # and concatenate the values\n",
    "        x = torch.cat([assignment, values], dim=1)\n",
    "        \n",
    "        x = F.relu(self.drop1(self.lin1(x)))\n",
    "        x = F.relu(self.lin2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with dueling networks\n",
    "class DuelingDQN(nn.Module):\n",
    "\n",
    "    def __init__(self, n, m, embedding_size=8, units=128):\n",
    "        super(DuelingDQN, self).__init__()\n",
    "        # The assignment becomes embedded, so it has size m * embedding_size\n",
    "        # when flattened\n",
    "        # The n comes from the values attached\n",
    "        self.assignment_size = m * embedding_size\n",
    "        self.input_size = self.assignment_size + n\n",
    "        self.output_size = m * n\n",
    "        self.n = n\n",
    "        self.m = m\n",
    "      \n",
    "        self.units = units\n",
    "\n",
    "        self.embedding_size = embedding_size\n",
    "        # Embed the targets, since the actual numerical value of the\n",
    "        # targets don't mean anything\n",
    "        # Another idea: skip the middleman and replace the targets\n",
    "        # with the target values\n",
    "        self.embedding = nn.Embedding(n, self.embedding_size)\n",
    "        self.lin1 = nn.Linear(self.input_size, units)\n",
    "        self.drop1 = nn.Dropout(0.2)\n",
    "\n",
    "        # Layer to measure the value of a state\n",
    "        self.value_stream = nn.Sequential(\n",
    "            nn.Linear(units, units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(units, 1)\n",
    "        )\n",
    "        # Layer to measure the advantages of an action given a state\n",
    "        self.advantage_stream = nn.Sequential(\n",
    "            nn.Linear(units, units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(units, self.output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, state):\n",
    "        assignment = state[:, :self.m].long()\n",
    "        assignment = self.embedding(assignment)\n",
    "\n",
    "\n",
    "        values = state[:, self.m:].float()\n",
    "\n",
    "        # Flatten the assignment embedding\n",
    "        assignment = assignment.view(-1, self.assignment_size).float() \n",
    "        \n",
    "        # and concatenate the values\n",
    "        x = torch.cat([assignment, values], dim=1)\n",
    "        x = F.relu(self.drop1(self.lin1(x)))\n",
    "        values = self.value_stream(x)\n",
    "        advantages = self.advantage_stream(x)\n",
    "        qvals = values + (advantages - advantages.mean())\n",
    "        \n",
    "        return qvals\n",
    "\n",
    "    def feature_size(self):\n",
    "        return self.conv(autograd.Variable(torch.zeros(1, *self.input_dim))).view(1, -1).size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.999\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 200\n",
    "TARGET_UPDATE = 100\n",
    "MAX_ITERATIONS = 500\n",
    "\n",
    "# n - number of targets\n",
    "n = 10\n",
    "# m - number of weapons\n",
    "m = 10\n",
    "assert n > 1\n",
    "\n",
    "lower_val = 25\n",
    "upper_val = 50\n",
    "lower_prob = 0.6\n",
    "upper_prob = 0.9\n",
    "prob = np.random.uniform(lower_prob, upper_prob, (m, n))\n",
    "env = WTAEnv(n, m, lower_val, upper_val, prob, device)\n",
    "\n",
    "policy_net = DuelingDQN(n, m, n // 2, 64).to(device)\n",
    "target_net = DuelingDQN(n, m, n // 2, 64).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "\n",
    "optimizer = optim.RMSprop(policy_net.parameters())\n",
    "memory = ReplayMemory(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 646
    },
    "colab_type": "code",
    "id": "bJQI_SFNl2h6",
    "outputId": "bd33e174-0765-4f58-87e8-472a5caaf45d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 0/100, iteration 499/500 loss: 5.8840025105259555\n",
      "episode 1/100, iteration 499/500 loss: 7.3611644438087015\n",
      "episode 2/100, iteration 499/500 loss: 8.8494648185672866\n",
      "episode 3/100, iteration 499/500 loss: 9.3950749501982295\n",
      "episode 4/100, iteration 499/500 loss: 9.9418614108687856\n",
      "episode 5/100, iteration 499/500 loss: 7.8875163319293975\n",
      "episode 6/100, iteration 499/500 loss: 6.8261143134405475\n",
      "episode 7/100, iteration 499/500 loss: 6.0164856033015775\n",
      "episode 8/100, iteration 499/500 loss: 5.7311380091307195\n",
      "episode 9/100, iteration 499/500 loss: 5.0359611366675815\n",
      "episode 10/100, iteration 499/500 loss: 5.2490144785467097\n",
      "episode 11/100, iteration 499/500 loss: 5.6416055040288695\n",
      "episode 12/100, iteration 499/500 loss: 3.5172101336051944\n",
      "episode 13/100, iteration 499/500 loss: 3.4213916449658845\n",
      "episode 14/100, iteration 499/500 loss: 3.7401741737965594\n",
      "episode 15/100, iteration 499/500 loss: 3.5673652956385163\n",
      "episode 16/100, iteration 499/500 loss: 3.1751930075187385\n",
      "episode 17/100, iteration 499/500 loss: 3.6042441125321147\n",
      "episode 18/100, iteration 499/500 loss: 2.0372083734544546\n",
      "episode 19/100, iteration 499/500 loss: 3.2378855490400695\n",
      "episode 20/100, iteration 499/500 loss: 2.3567849548367617\n",
      "episode 21/100, iteration 499/500 loss: 1.4874302438590403\n",
      "episode 22/100, iteration 499/500 loss: 0.69682657618783525\n",
      "episode 23/100, iteration 499/500 loss: 1.38470703370871646\n",
      "episode 24/100, iteration 499/500 loss: 1.12994221247910455\n",
      "episode 25/100, iteration 499/500 loss: 0.31888027090230936\n",
      "episode 26/100, iteration 499/500 loss: 0.42806285763730856\n",
      "episode 27/100, iteration 499/500 loss: 0.49701603789279256\n",
      "episode 28/100, iteration 499/500 loss: 0.37133775558386445\n",
      "episode 29/100, iteration 499/500 loss: 1.68734800519689852\n",
      "episode 30/100, iteration 499/500 loss: 1.49889652352376263\n",
      "episode 31/100, iteration 499/500 loss: 0.695528496098254647\n",
      "episode 32/100, iteration 499/500 loss: 0.56897474349233926\n",
      "episode 33/100, iteration 499/500 loss: 1.04243919360678587\n",
      "episode 34/100, iteration 499/500 loss: 0.53415798076406935\n",
      "episode 35/100, iteration 499/500 loss: 1.70025978275211266\n",
      "episode 36/100, iteration 499/500 loss: 1.14655795101571816\n",
      "episode 37/100, iteration 499/500 loss: 0.81718687720061014\n",
      "episode 38/100, iteration 499/500 loss: 0.83463484795606984\n",
      "episode 39/100, iteration 499/500 loss: 0.54985675773560946\n",
      "episode 40/100, iteration 499/500 loss: 2.61420391723419785\n",
      "episode 41/100, iteration 499/500 loss: 1.73984098797474526\n",
      "episode 42/100, iteration 499/500 loss: 0.83396533989254715\n",
      "episode 43/100, iteration 499/500 loss: 0.61668383691977567\n",
      "episode 44/100, iteration 499/500 loss: 0.829064923199878136\n",
      "episode 45/100, iteration 499/500 loss: 1.65747964009850467\n",
      "episode 46/100, iteration 499/500 loss: 0.48825042213779954\n",
      "episode 47/100, iteration 499/500 loss: 0.55732736441894357\n",
      "episode 48/100, iteration 499/500 loss: 2.19618688950940889\n",
      "episode 49/100, iteration 499/500 loss: 0.422396527516765835\n",
      "episode 50/100, iteration 499/500 loss: 1.470911000981062974\n",
      "episode 51/100, iteration 499/500 loss: 0.93557104363649954\n",
      "episode 52/100, iteration 499/500 loss: 0.31201638949965504\n",
      "episode 53/100, iteration 499/500 loss: 0.72226266903506784\n",
      "episode 54/100, iteration 499/500 loss: 0.80560418041968656\n",
      "episode 55/100, iteration 499/500 loss: 0.54814276384885034\n",
      "episode 56/100, iteration 499/500 loss: 0.73023267392347616\n",
      "episode 57/100, iteration 499/500 loss: 0.67311857369652024\n",
      "episode 58/100, iteration 499/500 loss: 1.23121142583893865\n",
      "episode 59/100, iteration 499/500 loss: 1.37943096547322225\n",
      "episode 60/100, iteration 499/500 loss: 0.71509416342067735\n",
      "episode 61/100, iteration 499/500 loss: 0.080308709170275635\n",
      "episode 62/100, iteration 499/500 loss: 0.23448779278069882\n",
      "episode 63/100, iteration 499/500 loss: 1.71727924374713278\n",
      "episode 64/100, iteration 499/500 loss: 0.352225741354184945\n",
      "episode 65/100, iteration 499/500 loss: 0.22106291867220074\n",
      "episode 66/100, iteration 499/500 loss: 1.02838754303371737\n",
      "episode 67/100, iteration 499/500 loss: 0.495800124131087676\n",
      "episode 68/100, iteration 499/500 loss: 0.83022256946704023\n",
      "episode 69/100, iteration 499/500 loss: 1.41329970884852665\n",
      "episode 70/100, iteration 499/500 loss: 0.540432887695899744\n",
      "episode 71/100, iteration 499/500 loss: 0.36380720520720086\n",
      "episode 72/100, iteration 499/500 loss: 2.49358331614007075\n",
      "episode 73/100, iteration 499/500 loss: 1.58807409820894925\n",
      "episode 74/100, iteration 499/500 loss: 0.67110546545767497\n",
      "episode 75/100, iteration 499/500 loss: 0.66141384311364382\n",
      "episode 76/100, iteration 499/500 loss: 2.39093115415530336\n",
      "episode 77/100, iteration 499/500 loss: 1.62683622624347086\n",
      "episode 78/100, iteration 499/500 loss: 2.73890662505628248\n",
      "episode 79/100, iteration 499/500 loss: 1.23097021271369836\n",
      "episode 80/100, iteration 499/500 loss: 3.374604461365864355\n",
      "episode 81/100, iteration 499/500 loss: 0.80565174782839675\n",
      "episode 82/100, iteration 499/500 loss: 0.62725824358184862\n",
      "episode 83/100, iteration 499/500 loss: 0.12945882273810205\n",
      "episode 84/100, iteration 499/500 loss: 0.45406778733165933\n",
      "episode 85/100, iteration 499/500 loss: 0.21732651620228754\n",
      "episode 86/100, iteration 499/500 loss: 0.409730805041588855\n",
      "episode 87/100, iteration 499/500 loss: 0.47744098167496274\n",
      "episode 88/100, iteration 499/500 loss: 1.268887408372724666\n",
      "episode 89/100, iteration 499/500 loss: 0.13870214123125701\n",
      "episode 90/100, iteration 499/500 loss: 1.54567139054074137\n",
      "episode 91/100, iteration 499/500 loss: 1.72713617911297118\n",
      "episode 92/100, iteration 499/500 loss: 0.51987685508304865\n",
      "episode 93/100, iteration 499/500 loss: 2.352239840800268524\n",
      "episode 94/100, iteration 499/500 loss: 1.90709280811283582\n",
      "episode 95/100, iteration 499/500 loss: 0.948371399207914246\n",
      "episode 96/100, iteration 499/500 loss: 0.98479645067766253\n",
      "episode 97/100, iteration 499/500 loss: 0.67903402280338255\n",
      "episode 98/100, iteration 499/500 loss: 0.95129858789079766\n",
      "episode 99/100, iteration 499/500 loss: 0.93320256240282376\n",
      "\n",
      "Complete\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_episodes = 100\n",
    "# env.reset()\n",
    "# init_state = env.get_state()\n",
    "losses = []\n",
    "for i_episode in range(num_episodes):\n",
    "    # Initialize the environment and state\n",
    "    env.reset()\n",
    "    state = env.get_state()\n",
    "    for t in range(MAX_ITERATIONS):\n",
    "        # Select and perform an action\n",
    "        action = select_action(state)\n",
    "        observation, reward, done, _ = env.step(action)\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "\n",
    "        if not done:\n",
    "            next_state = observation\n",
    "        else:\n",
    "            next_state = None\n",
    "\n",
    "        # Store the transition in memory\n",
    "        memory.push(state, action, next_state, reward)\n",
    "\n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "\n",
    "        # Perform one step of the optimization (on the target network)\n",
    "        loss = optimize_model()\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "        \n",
    "        print(f'episode {i_episode}/{num_episodes}, iteration {t}/{MAX_ITERATIONS} loss: {loss}', end='\\r')\n",
    "    losses.append(loss)\n",
    "    print()\n",
    "    # Update the target network, copying all weights and biases in DQN\n",
    "    if i_episode % TARGET_UPDATE == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "print()\n",
    "print('Complete')\n",
    "env.render()\n",
    "env.close()\n",
    "\n",
    "x = np.arange(len(losses))\n",
    "plt.plot(x, losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DuelingDQN(\n",
       "  (embedding): Embedding(10, 5)\n",
       "  (lin1): Linear(in_features=60, out_features=64, bias=True)\n",
       "  (drop1): Dropout(p=0.2, inplace=False)\n",
       "  (value_stream): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       "  (advantage_stream): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=100, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_performance(runs, steps=10):\n",
    "    avg_improvement = 0\n",
    "    \n",
    "    for i in range(runs):\n",
    "        test_env = WTAEnv(n, m, lower_val, upper_val, prob, device)\n",
    "\n",
    "        init_value = test_env.value\n",
    "        improvement = 0\n",
    "        for j in range(steps):\n",
    "            state = test_env.get_state().unsqueeze(1).transpose(0, 1)\n",
    "            best_action = policy_net(state).max(1)[1]\n",
    "\n",
    "            _, change, _, _ = test_env.step(best_action)\n",
    "            improvement += change\n",
    "        \n",
    "        avg_improvement += (improvement / init_value)\n",
    "    \n",
    "    avg_improvement /= runs\n",
    "    \n",
    "    return avg_improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01938425416198859\n"
     ]
    }
   ],
   "source": [
    "# On average, how much does stepping according to the trained network improve the value of the assignment?\n",
    "# Is a percent improvement\n",
    "# any value >0 probably means some level of generalization\n",
    "print(test_performance(1000, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CS159_Project.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
