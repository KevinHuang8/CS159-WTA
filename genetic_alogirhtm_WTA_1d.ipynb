{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import copy\n",
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read example file\n",
    "def read_example_file(filename):\n",
    "    with open(filename) as fp:\n",
    "        prob_setting = list(map(lambda x: int(x), fp.readline().split()))\n",
    "        if len(prob_setting) == 1:\n",
    "            n_targets, n_weapons = prob_setting[0], prob_setting[0]\n",
    "        else:\n",
    "            n_targets, n_weapons = prob_setting\n",
    "\n",
    "        values = []\n",
    "        for i in range(n_targets):\n",
    "            values.append(float(fp.readline()))\n",
    "\n",
    "        probabilities = []\n",
    "        for i in range(n_weapons):\n",
    "            probabilities.append([])\n",
    "            for j in range(n_targets):\n",
    "                probabilities[i].append(float(fp.readline()))\n",
    "    return n_targets, n_weapons, values, probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN-related code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Take in n by m matrix, convert it to 1D feature vector '''\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, n, m, embedding_size=8, units=64):\n",
    "        super(DQN, self).__init__()\n",
    "        # The assignment becomes embedded, so it has size m * embedding_size\n",
    "        # when flattened\n",
    "        # The n comes from the values attached\n",
    "        self.assignment_size = m * embedding_size\n",
    "        self.input_size = self.assignment_size + n\n",
    "        self.output_size = m * n\n",
    "        self.n = n\n",
    "        self.m = m\n",
    "    \n",
    "        self.embedding_size = embedding_size\n",
    "        # Embed the targets, since the actual numerical value of the\n",
    "        # targets don't mean anything\n",
    "        # Another idea: skip the middleman and replace the targets\n",
    "        # with the target values\n",
    "        self.embedding = nn.Embedding(n, self.embedding_size)\n",
    "        self.lin1 = nn.Linear(self.input_size, units)\n",
    "        self.drop1 = nn.Dropout(0.2)\n",
    "        self.lin2 = nn.Linear(units, self.output_size)\n",
    "        self.drop2 = nn.Dropout(0.2)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, state):\n",
    "        assignment = state[:, :self.m].long()\n",
    "        assignment = self.embedding(assignment)\n",
    "        \n",
    "        values = state[:, self.m:].float()\n",
    "                \n",
    "        # Flatten the assignment embedding\n",
    "        assignment = assignment.view(-1, self.assignment_size).float() \n",
    "        \n",
    "        # and concatenate the values\n",
    "        x = torch.cat([assignment, values], dim=1)\n",
    "        \n",
    "        x = F.relu(self.drop1(self.lin1(x)))\n",
    "        x = F.relu(self.lin2(x))\n",
    "        return x\n",
    "\n",
    "# with dueling networks\n",
    "class DuelingDQN(nn.Module):\n",
    "\n",
    "    def __init__(self, n, m, embedding_size=8, units=128):\n",
    "        super(DuelingDQN, self).__init__()\n",
    "        # The assignment becomes embedded, so it has size m * embedding_size\n",
    "        # when flattened\n",
    "        # The n comes from the values attached\n",
    "        self.assignment_size = m * embedding_size\n",
    "        self.input_size = self.assignment_size + n\n",
    "        self.output_size = m * n\n",
    "        self.n = n\n",
    "        self.m = m\n",
    "      \n",
    "        self.units = units\n",
    "\n",
    "        self.embedding_size = embedding_size\n",
    "        # Embed the targets, since the actual numerical value of the\n",
    "        # targets don't mean anything\n",
    "        # Another idea: skip the middleman and replace the targets\n",
    "        # with the target values\n",
    "        self.embedding = nn.Embedding(n, self.embedding_size)\n",
    "        self.lin1 = nn.Linear(self.input_size, units)\n",
    "        self.drop1 = nn.Dropout(0.2)\n",
    "\n",
    "        # Layer to measure the value of a state\n",
    "        self.value_stream = nn.Sequential(\n",
    "            nn.Linear(units, units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(units, 1)\n",
    "        )\n",
    "        # Layer to measure the advantages of an action given a state\n",
    "        self.advantage_stream = nn.Sequential(\n",
    "            nn.Linear(units, units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(units, self.output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, state):\n",
    "        assignment = state[:, :self.m].long()\n",
    "        assignment = self.embedding(assignment)\n",
    "\n",
    "\n",
    "        values = state[:, self.m:].float()\n",
    "\n",
    "        # Flatten the assignment embedding\n",
    "        assignment = assignment.view(-1, self.assignment_size).float() \n",
    "        \n",
    "        # and concatenate the values\n",
    "        x = torch.cat([assignment, values], dim=1)\n",
    "        x = F.relu(self.drop1(self.lin1(x)))\n",
    "        values = self.value_stream(x)\n",
    "        advantages = self.advantage_stream(x)\n",
    "        qvals = values + (advantages - advantages.mean())\n",
    "        \n",
    "        return qvals\n",
    "\n",
    "    def feature_size(self):\n",
    "        return self.conv(autograd.Variable(torch.zeros(1, *self.input_dim))).view(1, -1).size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_possible(state, weapon, target):\n",
    "    '''\n",
    "    We don't want to assign a weapon to the target if it is already assigned\n",
    "    to the target, since this does not change the state at all.\n",
    "    '''\n",
    "    curr_target = state[weapon].item()\n",
    "    return curr_target != target \n",
    "\n",
    "def select_action(model, state, n):\n",
    "    # state: 1 * (n + m) tensor\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        state_batch = torch.unsqueeze(state, 1).transpose(0, 1).float()\n",
    "        largest = torch.sort(model(state_batch), descending=True, dim=1)[1]\n",
    "        model.train()\n",
    "\n",
    "        # Try until we get a valid action\n",
    "        for i in largest[0]:\n",
    "            weapon = i / n\n",
    "            target = i % n\n",
    "\n",
    "            if is_possible(state, weapon.item(), target.item()):\n",
    "                return torch.tensor([i], device=device)\n",
    "\n",
    "        # This should never happen\n",
    "        raise ValueError('Invalid state: no possible action')\n",
    "        \n",
    "def decode_action(action, n):\n",
    "        '''\n",
    "        Given an action, return the weapon and target associated with\n",
    "        that action.\n",
    "        '''\n",
    "        return action // n, action % n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WTA_1D_General_GA:\n",
    "    def __init__(self, config, example_number, mutation_method='random'):\n",
    "        self.config = config\n",
    "        # n_targets: number of targets, n_weapons: number of weapons\n",
    "        # values: list of target values (size: n_targets)\n",
    "        # probabilities: list of destruction probabilities (size: n_weapons x n_targets)\n",
    "        self.n_targets, self.n_weapons, self.values, self.probabilities = read_example_file(config['example_file'])\n",
    "        # state: list of assignments (size: population_size x n_weapons, 0-indexed for target of each weapon)\n",
    "        self.state = self.generate_initial_population(config['population_size'])\n",
    "        self.good_gene_dict = self.get_good_gene_dict()\n",
    "        self.mutation_method = mutation_method\n",
    "        self.dqn_model = torch.load('./trained_models/WTA{}'.format(example_number), map_location=torch.device('cpu'))\n",
    "        self.dqn_model.eval()\n",
    "        self.dueling_dqn_model = torch.load('./trained_models/WTA{}_dueling'.format(example_number), map_location=torch.device('cpu'))\n",
    "        self.dueling_dqn_model.eval()\n",
    "    \n",
    "    # get the best target for each weapon (used for ex_crossover)\n",
    "    def get_good_gene_dict(self):\n",
    "        good_gene_dict = {}\n",
    "        for i in range(self.n_weapons):\n",
    "            weapon_target_edv_list = []\n",
    "            for j in range(self.n_targets):\n",
    "                weapon_target_edv_list.append(self.values[j] * self.probabilities[i][j])\n",
    "            good_gene = weapon_target_edv_list.index(max(weapon_target_edv_list))\n",
    "            good_gene_dict[i] = good_gene\n",
    "                \n",
    "        return good_gene_dict\n",
    "    \n",
    "    # update state after crossover\n",
    "    def ocp_crossover(self, population):\n",
    "        crossover_state = []\n",
    "        for _ in range(self.config['population_size']):\n",
    "            father, mother = random.sample(population, 2)\n",
    "            point = random.randint(0, self.n_weapons-1)\n",
    "            child = father[:point] + mother[point:]\n",
    "            crossover_state.append(child)\n",
    "        return crossover_state\n",
    "    \n",
    "    # ex crossover as explained in the paper\n",
    "    # repeat the following process for m_c < n_target times\n",
    "    # 1. find genes (weapon-target pair) with the same value of target in both parents\n",
    "    # 2. inherit good genes (good gene defined as the maximum target for each weapon)\n",
    "    # 3. randomly select two genes not inhereited from parents\n",
    "    # 4. exchange genes to generate offspring\n",
    "    def ex_crossover(self, population):\n",
    "        pool = []\n",
    "        population = copy.deepcopy(population)\n",
    "        for _ in range(self.config['n_offsprings'] // 2):\n",
    "            father, mother = random.sample(population, 2)\n",
    "            child1, child2 = father, mother\n",
    "            for _ in range(self.config['m_c']):\n",
    "                # step 2\n",
    "                inherited_gene_list = []\n",
    "                for i in range(self.n_weapons):\n",
    "                    if father[i] == mother[i] and father[i] == self.good_gene_dict[i]: # inherit to child\n",
    "                        inherited_gene_list.append(i)\n",
    "                gene_swap_candidates = set(range(self.n_weapons)) - set(inherited_gene_list)\n",
    "                if len(gene_swap_candidates) < 2:\n",
    "                    break\n",
    "\n",
    "                # step 3\n",
    "                swap_idx1, swap_idx2 = random.sample(gene_swap_candidates, 2)\n",
    "                child1[swap_idx1], child2[swap_idx2] = child2[swap_idx2], child1[swap_idx1]\n",
    "                child1[swap_idx2], child2[swap_idx1] = child2[swap_idx1], child1[swap_idx2]\n",
    "            \n",
    "            pool.append(child1)\n",
    "            pool.append(child2)\n",
    "        return pool\n",
    "\n",
    "    # update state after mutation\n",
    "    \"\"\"\n",
    "    def mutate(self, learner):\n",
    "        mutated_state = []\n",
    "        for assignment in self.state:\n",
    "            mutated_assignment = learner.get_mutation(assignment)\n",
    "            mutated_state.append(mutated_assignment)\n",
    "        self.state = mutated_state\n",
    "    \"\"\"\n",
    "    def mutate_random(self, population):\n",
    "        mutated_population = []\n",
    "        for assignment in population:\n",
    "            for _ in range(self.config['m_m']):\n",
    "                # choose random gene\n",
    "                mutated_weapon = random.sample(list(range(self.n_weapons)), 1)[0]\n",
    "                mutated_target = random.sample(list(range(self.n_targets)), 1)[0]\n",
    "                assignment[mutated_weapon] = mutated_target\n",
    "            mutated_population.append(assignment)\n",
    "        return mutated_population\n",
    "    \n",
    "    def mutate_dqn(self, population, model_type):\n",
    "        mutated_population = []\n",
    "        for assignment in population:\n",
    "            for _ in range(self.config['m_m']):\n",
    "                state = torch.tensor(np.concatenate([assignment, self.values]), device=torch.device('cpu'))\n",
    "                if model_type == 'dqn':\n",
    "                    action = select_action(self.dqn_model, state, self.n_weapons)\n",
    "                elif model_type == 'dueling_dqn':\n",
    "                    action = select_action(self.dueling_dqn_model, state, self.n_weapons)\n",
    "                mutated_weapon, mutated_target = decode_action(action, self.n_weapons)\n",
    "                mutated_weapon, mutated_target = mutated_weapon.numpy()[0], mutated_target.numpy()[0]\n",
    "                assignment[mutated_weapon] = mutated_target\n",
    "            mutated_population.append(assignment)\n",
    "        return mutated_population\n",
    "    \n",
    "    def reward(self, assignment):\n",
    "        survival_probabilities = [1] * self.n_targets\n",
    "        for i in range(self.n_weapons):\n",
    "            survival_probabilities[assignment[i]] *= 1 - self.probabilities[i][assignment[i]]\n",
    "        reward = 0\n",
    "        for j in range(self.n_targets):\n",
    "            reward += self.values[j] * (1 - survival_probabilities[j])\n",
    "        return reward\n",
    "    \n",
    "    # choose the best population from the pool of population + offspring\n",
    "    def evolution_strategy(self, pool):\n",
    "        pool = sorted(pool, key = lambda x: self.reward(x), reverse=True)\n",
    "        return pool[:self.config['population_size']]\n",
    "    \n",
    "    # helper functions\n",
    "    def generate_initial_population(self, population_size):\n",
    "        population = []\n",
    "        targets = list(range(self.n_targets))\n",
    "        for i in range(population_size):\n",
    "            assignment = [random.choice(targets) for _ in range(self.n_weapons)]\n",
    "            population.append(assignment)\n",
    "        return population\n",
    "    \n",
    "    def reset(self):\n",
    "        self.state = [-1] * self.n_weapons\n",
    "        \n",
    "    def run(self, max_iter, verbose=False):\n",
    "        population = self.generate_initial_population(self.config['population_size'])\n",
    "#         print('initial population', population)\n",
    "        assert self.mutation_method in ['random', 'dqn', 'dueling_dqn']\n",
    "        for i_iter in range(max_iter):\n",
    "            pool = self.ex_crossover(population)\n",
    "            if self.mutation_method == 'random':\n",
    "                pool = self.mutate_random(pool)\n",
    "            elif self.mutation_method == 'dqn':\n",
    "                pool = self.mutate_dqn(pool, self.mutation_method)\n",
    "            elif self.mutation_method == 'dueling_dqn':\n",
    "                pool = self.mutate_dqn(pool, self.mutation_method)\n",
    "            population = self.evolution_strategy(pool + population)\n",
    "            if all(x == population[0] for x in population):\n",
    "                if verbose:\n",
    "                    print('converged in iter {}'.format(i_iter+1))\n",
    "                break\n",
    "                \n",
    "            if verbose:\n",
    "                if (i_iter + 1) % 40 == 0:\n",
    "                    print('iter {}: reward = {:.2f}'.format(i_iter+1, max(map(lambda x: self.reward(x), population))))\n",
    "                    candidates = copy.deepcopy(population)\n",
    "                    candidates = sorted(candidates, key = lambda x: self.reward(x), reverse=True)\n",
    "                    print(candidates[0])\n",
    "        population = sorted(population, key = lambda x: self.reward(x), reverse=True)\n",
    "        return population[0], self.reward(population[0]), i_iter+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'example_file': './examples/WTA1',\n",
    "    'population_size': 50,\n",
    "    'n_offsprings': 50,\n",
    "    'm_c': 1,\n",
    "    'm_m': 1 # for fair comparison set m_m to 1 \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 40: reward = 328.64\n",
      "[4, 3, 2, 1, 0]\n",
      "iter 80: reward = 328.64\n",
      "[4, 3, 2, 1, 0]\n",
      "iter 120: reward = 328.64\n",
      "[4, 3, 2, 1, 0]\n",
      "iter 160: reward = 328.64\n",
      "[4, 3, 2, 1, 0]\n",
      "iter 200: reward = 328.64\n",
      "[4, 3, 2, 1, 0]\n",
      "iter 240: reward = 328.64\n",
      "[4, 3, 2, 1, 0]\n",
      "iter 280: reward = 328.64\n",
      "[4, 3, 2, 1, 0]\n",
      "iter 320: reward = 328.64\n",
      "[4, 3, 2, 1, 0]\n",
      "iter 360: reward = 328.64\n",
      "[4, 3, 2, 1, 0]\n",
      "iter 400: reward = 328.64\n",
      "[4, 3, 2, 1, 0]\n",
      "iter 440: reward = 328.64\n",
      "[4, 3, 2, 1, 0]\n",
      "iter 480: reward = 328.64\n",
      "[4, 3, 2, 1, 0]\n",
      "iter 520: reward = 328.64\n",
      "[4, 3, 2, 1, 0]\n",
      "iter 560: reward = 328.64\n",
      "[4, 3, 2, 1, 0]\n",
      "iter 600: reward = 328.64\n",
      "[4, 3, 2, 1, 0]\n",
      "iter 640: reward = 328.64\n",
      "[4, 3, 2, 1, 0]\n",
      "iter 680: reward = 328.64\n",
      "[4, 3, 2, 1, 0]\n",
      "iter 720: reward = 328.64\n",
      "[4, 3, 2, 1, 0]\n",
      "iter 760: reward = 328.64\n",
      "[4, 3, 2, 1, 0]\n",
      "iter 800: reward = 328.64\n",
      "[4, 3, 2, 1, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([4, 3, 2, 1, 0], 328.636, 800)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wta_1d = WTA_1D_General_GA(config, 1, mutation_method='dqn')\n",
    "\n",
    "wta_1d.run(800, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WTA1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_WEAPONS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m_population: 5, m_offsprings: 5 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 159\n",
      "m_population: 5, m_offsprings: 10 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 64\n",
      "m_population: 5, m_offsprings: 15 - result: [4, 3, 2, 1, 4], reward: 310.192, convergence: 18\n",
      "m_population: 5, m_offsprings: 20 - result: [4, 0, 3, 1, 2], reward: 291.488, convergence: 3\n",
      "m_population: 5, m_offsprings: 25 - result: [1, 3, 2, 4, 1], reward: 298.549, convergence: 3\n",
      "m_population: 5, m_offsprings: 30 - result: [4, 3, 2, 1, 2], reward: 304.721, convergence: 18\n",
      "m_population: 10, m_offsprings: 5 - result: [0, 3, 2, 1, 4], reward: 327.082, convergence: 89\n",
      "m_population: 10, m_offsprings: 10 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 245\n",
      "m_population: 10, m_offsprings: 15 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 229\n",
      "m_population: 10, m_offsprings: 20 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 420\n",
      "m_population: 10, m_offsprings: 25 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 294\n",
      "m_population: 10, m_offsprings: 30 - result: [0, 3, 2, 1, 4], reward: 327.082, convergence: 802\n",
      "m_population: 15, m_offsprings: 5 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 352\n",
      "m_population: 15, m_offsprings: 10 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 194\n",
      "m_population: 15, m_offsprings: 15 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 207\n",
      "m_population: 15, m_offsprings: 20 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 166\n",
      "m_population: 15, m_offsprings: 25 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 183\n",
      "m_population: 15, m_offsprings: 30 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 708\n",
      "m_population: 20, m_offsprings: 5 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 403\n",
      "m_population: 20, m_offsprings: 10 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 214\n",
      "m_population: 20, m_offsprings: 15 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 192\n",
      "m_population: 20, m_offsprings: 20 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 218\n",
      "m_population: 20, m_offsprings: 25 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 197\n",
      "m_population: 20, m_offsprings: 30 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 196\n",
      "m_population: 25, m_offsprings: 5 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 596\n",
      "m_population: 25, m_offsprings: 10 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 267\n",
      "m_population: 25, m_offsprings: 15 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 195\n",
      "m_population: 25, m_offsprings: 20 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 221\n",
      "m_population: 25, m_offsprings: 25 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 192\n",
      "m_population: 25, m_offsprings: 30 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 172\n",
      "m_population: 30, m_offsprings: 5 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 790\n",
      "m_population: 30, m_offsprings: 10 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 333\n",
      "m_population: 30, m_offsprings: 15 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 250\n",
      "m_population: 30, m_offsprings: 20 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 231\n",
      "m_population: 30, m_offsprings: 25 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 172\n",
      "m_population: 30, m_offsprings: 30 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 162\n"
     ]
    }
   ],
   "source": [
    "fpout = open('./experiments/WTA1/random_mutation.csv', 'w')\n",
    "wr = csv.writer(fpout, delimiter=',')\n",
    "wr.writerow(['population_multiplier, offsprings_multiplier, result, reward, convergence_iter'])\n",
    "for m_population in range(5, 31, 5): # population multiplier\n",
    "    for m_offsprings in range(5, 31, 5): # offsprings multiplier\n",
    "        config = {\n",
    "            'example_file': './examples/WTA1',\n",
    "            'population_size': N_WEAPONS * m_population,\n",
    "            'n_offsprings': N_WEAPONS * m_offsprings,\n",
    "            'm_c': 1,\n",
    "            'm_m': 1 # for fair comparison set m_m to 1\n",
    "        }\n",
    "        wta_1d = WTA_1D_General_GA(config, 1, mutation_method='random')\n",
    "        result, reward, convergence_iter = wta_1d.run(1000, verbose=False)\n",
    "        print('m_population: {}, m_offsprings: {} - result: {}, reward: {:.3f}, convergence: {}'.format(m_population, m_offsprings, result, reward, convergence_iter))\n",
    "        wr.writerow([m_population, m_offsprings, '_'.join(map(lambda x: str(x), result)), '{:.3f}'.format(reward), convergence_iter])\n",
    "        \n",
    "fpout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m_population: 5, m_offsprings: 5 - result: [0, 3, 2, 1, 4], reward: 327.082, convergence: 14\n",
      "m_population: 5, m_offsprings: 10 - result: [2, 3, 0, 1, 4], reward: 319.545, convergence: 3\n",
      "m_population: 5, m_offsprings: 15 - result: [2, 0, 1, 3, 4], reward: 300.508, convergence: 5\n",
      "m_population: 5, m_offsprings: 20 - result: [0, 3, 2, 1, 4], reward: 327.082, convergence: 5\n",
      "m_population: 5, m_offsprings: 25 - result: [0, 3, 2, 1, 4], reward: 327.082, convergence: 7\n",
      "m_population: 5, m_offsprings: 30 - result: [0, 3, 2, 1, 4], reward: 327.082, convergence: 3\n",
      "m_population: 10, m_offsprings: 5 - result: [0, 3, 2, 1, 4], reward: 327.082, convergence: 40\n",
      "m_population: 10, m_offsprings: 10 - result: [0, 3, 2, 1, 4], reward: 327.082, convergence: 18\n",
      "m_population: 10, m_offsprings: 15 - result: [0, 3, 2, 1, 4], reward: 327.082, convergence: 14\n",
      "m_population: 10, m_offsprings: 20 - result: [0, 3, 2, 1, 4], reward: 327.082, convergence: 14\n",
      "m_population: 10, m_offsprings: 25 - result: [0, 3, 2, 1, 4], reward: 327.082, convergence: 14\n",
      "m_population: 10, m_offsprings: 30 - result: [0, 3, 2, 1, 4], reward: 327.082, convergence: 8\n",
      "m_population: 15, m_offsprings: 5 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 1000\n",
      "m_population: 15, m_offsprings: 10 - result: [0, 3, 2, 1, 4], reward: 327.082, convergence: 13\n",
      "m_population: 15, m_offsprings: 15 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 1000\n",
      "m_population: 15, m_offsprings: 20 - result: [0, 3, 2, 1, 4], reward: 327.082, convergence: 19\n",
      "m_population: 15, m_offsprings: 25 - result: [0, 3, 2, 1, 4], reward: 327.082, convergence: 14\n",
      "m_population: 15, m_offsprings: 30 - result: [0, 3, 2, 1, 4], reward: 327.082, convergence: 11\n",
      "m_population: 20, m_offsprings: 5 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 1000\n",
      "m_population: 20, m_offsprings: 10 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 1000\n",
      "m_population: 20, m_offsprings: 15 - result: [0, 3, 2, 1, 4], reward: 327.082, convergence: 18\n",
      "m_population: 20, m_offsprings: 20 - result: [0, 3, 2, 1, 4], reward: 327.082, convergence: 16\n",
      "m_population: 20, m_offsprings: 25 - result: [0, 3, 2, 1, 4], reward: 327.082, convergence: 16\n",
      "m_population: 20, m_offsprings: 30 - result: [0, 3, 2, 1, 4], reward: 327.082, convergence: 18\n",
      "m_population: 25, m_offsprings: 5 - result: [0, 3, 2, 1, 4], reward: 327.082, convergence: 93\n",
      "m_population: 25, m_offsprings: 10 - result: [0, 3, 2, 1, 4], reward: 327.082, convergence: 52\n",
      "m_population: 25, m_offsprings: 15 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 1000\n",
      "m_population: 25, m_offsprings: 20 - result: [0, 3, 2, 1, 4], reward: 327.082, convergence: 19\n",
      "m_population: 25, m_offsprings: 25 - result: [0, 3, 2, 1, 4], reward: 327.082, convergence: 17\n",
      "m_population: 25, m_offsprings: 30 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 1000\n",
      "m_population: 30, m_offsprings: 5 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 1000\n",
      "m_population: 30, m_offsprings: 10 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 1000\n",
      "m_population: 30, m_offsprings: 15 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 1000\n",
      "m_population: 30, m_offsprings: 20 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 1000\n",
      "m_population: 30, m_offsprings: 25 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 1000\n",
      "m_population: 30, m_offsprings: 30 - result: [0, 3, 2, 1, 4], reward: 327.082, convergence: 16\n"
     ]
    }
   ],
   "source": [
    "fpout = open('./experiments/WTA1/dqn_mutation.csv', 'w')\n",
    "wr = csv.writer(fpout, delimiter=',')\n",
    "wr.writerow(['population_multiplier, offsprings_multiplier, result, reward, convergence_iter'])\n",
    "for m_population in range(5, 31, 5): # population multiplier\n",
    "    for m_offsprings in range(5, 31, 5): # offsprings multiplier\n",
    "        config = {\n",
    "            'example_file': './examples/WTA1',\n",
    "            'population_size': N_WEAPONS * m_population,\n",
    "            'n_offsprings': N_WEAPONS * m_offsprings,\n",
    "            'm_c': 1,\n",
    "            'm_m': 1 # for fair comparison set m_m to 1\n",
    "        }\n",
    "        wta_1d = WTA_1D_General_GA(config, 1, mutation_method='dqn')\n",
    "        result, reward, convergence_iter = wta_1d.run(1000, verbose=False)\n",
    "        print('m_population: {}, m_offsprings: {} - result: {}, reward: {:.3f}, convergence: {}'.format(m_population, m_offsprings, result, reward, convergence_iter))\n",
    "        wr.writerow([m_population, m_offsprings, '_'.join(map(lambda x: str(x), result)), '{:.3f}'.format(reward), convergence_iter])\n",
    "        \n",
    "fpout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m_population: 5, m_offsprings: 5 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 165\n",
      "m_population: 5, m_offsprings: 10 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 626\n",
      "m_population: 5, m_offsprings: 15 - result: [2, 3, 0, 1, 4], reward: 319.545, convergence: 212\n",
      "m_population: 5, m_offsprings: 20 - result: [2, 3, 0, 1, 4], reward: 319.545, convergence: 1000\n",
      "m_population: 5, m_offsprings: 25 - result: [4, 3, 0, 1, 2], reward: 310.818, convergence: 1\n",
      "m_population: 5, m_offsprings: 30 - result: [4, 3, 0, 1, 2], reward: 310.818, convergence: 1\n",
      "m_population: 10, m_offsprings: 5 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 110\n",
      "m_population: 10, m_offsprings: 10 - result: [4, 3, 0, 1, 2], reward: 310.818, convergence: 5\n",
      "m_population: 10, m_offsprings: 15 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 200\n",
      "m_population: 10, m_offsprings: 20 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 261\n",
      "m_population: 10, m_offsprings: 25 - result: [4, 3, 0, 1, 2], reward: 310.818, convergence: 2\n",
      "m_population: 10, m_offsprings: 30 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 1000\n",
      "m_population: 15, m_offsprings: 5 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 241\n",
      "m_population: 15, m_offsprings: 10 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 115\n",
      "m_population: 15, m_offsprings: 15 - result: [4, 3, 0, 1, 2], reward: 310.818, convergence: 5\n",
      "m_population: 15, m_offsprings: 20 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 215\n",
      "m_population: 15, m_offsprings: 25 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 163\n",
      "m_population: 15, m_offsprings: 30 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 404\n",
      "m_population: 20, m_offsprings: 5 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 311\n",
      "m_population: 20, m_offsprings: 10 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 161\n",
      "m_population: 20, m_offsprings: 15 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 93\n",
      "m_population: 20, m_offsprings: 20 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 158\n",
      "m_population: 20, m_offsprings: 25 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 183\n",
      "m_population: 20, m_offsprings: 30 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 203\n",
      "m_population: 25, m_offsprings: 5 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 510\n",
      "m_population: 25, m_offsprings: 10 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 148\n",
      "m_population: 25, m_offsprings: 15 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 134\n",
      "m_population: 25, m_offsprings: 20 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 112\n",
      "m_population: 25, m_offsprings: 25 - result: [4, 3, 0, 1, 2], reward: 310.818, convergence: 4\n",
      "m_population: 25, m_offsprings: 30 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 178\n",
      "m_population: 30, m_offsprings: 5 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 601\n",
      "m_population: 30, m_offsprings: 10 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 163\n",
      "m_population: 30, m_offsprings: 15 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 117\n",
      "m_population: 30, m_offsprings: 20 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 111\n",
      "m_population: 30, m_offsprings: 25 - result: [4, 3, 0, 1, 2], reward: 310.818, convergence: 5\n",
      "m_population: 30, m_offsprings: 30 - result: [4, 3, 2, 1, 0], reward: 328.636, convergence: 144\n"
     ]
    }
   ],
   "source": [
    "fpout = open('./experiments/WTA1/dueling_dqn_mutation.csv', 'w')\n",
    "wr = csv.writer(fpout, delimiter=',')\n",
    "wr.writerow(['population_multiplier, offsprings_multiplier, result, reward, convergence_iter'])\n",
    "for m_population in range(5, 31, 5): # population multiplier\n",
    "    for m_offsprings in range(5, 31, 5): # offsprings multiplier\n",
    "        config = {\n",
    "            'example_file': './examples/WTA1',\n",
    "            'population_size': N_WEAPONS * m_population,\n",
    "            'n_offsprings': N_WEAPONS * m_offsprings,\n",
    "            'm_c': 1,\n",
    "            'm_m': 1 # for fair comparison set m_m to 1\n",
    "        }\n",
    "        wta_1d = WTA_1D_General_GA(config, 1, mutation_method='dueling_dqn')\n",
    "        result, reward, convergence_iter = wta_1d.run(1000, verbose=False)\n",
    "        print('m_population: {}, m_offsprings: {} - result: {}, reward: {:.3f}, convergence: {}'.format(m_population, m_offsprings, result, reward, convergence_iter))\n",
    "        wr.writerow([m_population, m_offsprings, '_'.join(map(lambda x: str(x), result)), '{:.3f}'.format(reward), convergence_iter])\n",
    "        \n",
    "fpout.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WTA2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_WEAPONS = 10\n",
    "max_iter = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m_population: 5, m_offsprings: 5 - result: [3, 8, 2, 6, 5, 0, 1, 4, 9, 7], reward: 622.688, convergence: 1762\n",
      "m_population: 5, m_offsprings: 10 - result: [2, 8, 7, 6, 5, 0, 1, 4, 9, 3], reward: 616.032, convergence: 2609\n",
      "m_population: 5, m_offsprings: 15 - result: [3, 8, 9, 6, 5, 0, 2, 4, 1, 7], reward: 620.031, convergence: 3000\n",
      "m_population: 5, m_offsprings: 20 - result: [2, 4, 8, 9, 0, 1, 7, 6, 9, 3], reward: 552.103, convergence: 1625\n",
      "m_population: 10, m_offsprings: 5 - result: [2, 8, 3, 6, 5, 0, 1, 4, 9, 7], reward: 619.627, convergence: 3000\n",
      "m_population: 10, m_offsprings: 10 - result: [3, 8, 2, 6, 5, 0, 1, 4, 9, 7], reward: 622.688, convergence: 2142\n",
      "m_population: 10, m_offsprings: 15 - result: [3, 8, 9, 6, 5, 0, 1, 4, 2, 7], reward: 618.250, convergence: 3000\n",
      "m_population: 10, m_offsprings: 20 - result: [3, 8, 2, 6, 5, 0, 1, 4, 9, 7], reward: 622.688, convergence: 3000\n",
      "m_population: 15, m_offsprings: 5 - result: [3, 8, 2, 6, 5, 0, 1, 4, 9, 7], reward: 622.688, convergence: 3000\n",
      "m_population: 15, m_offsprings: 10 - result: [3, 8, 2, 6, 5, 0, 1, 4, 9, 7], reward: 622.688, convergence: 3000\n",
      "m_population: 15, m_offsprings: 15 - result: [2, 8, 9, 6, 5, 0, 7, 4, 1, 3], reward: 617.339, convergence: 3000\n",
      "m_population: 15, m_offsprings: 20 - result: [3, 8, 9, 6, 5, 0, 2, 4, 1, 7], reward: 620.031, convergence: 3000\n",
      "m_population: 20, m_offsprings: 5 - result: [3, 8, 2, 6, 5, 0, 1, 4, 9, 7], reward: 622.688, convergence: 3000\n",
      "m_population: 20, m_offsprings: 10 - result: [3, 8, 2, 6, 5, 0, 1, 4, 9, 7], reward: 622.688, convergence: 3000\n",
      "m_population: 20, m_offsprings: 15 - result: [3, 8, 2, 6, 5, 0, 1, 4, 9, 7], reward: 622.688, convergence: 3000\n",
      "m_population: 20, m_offsprings: 20 - result: [3, 8, 2, 6, 5, 0, 1, 4, 9, 7], reward: 622.688, convergence: 2840\n"
     ]
    }
   ],
   "source": [
    "fpout = open('./experiments/WTA2/random_mutation.csv', 'w')\n",
    "wr = csv.writer(fpout, delimiter=',')\n",
    "wr.writerow(['population_multiplier, offsprings_multiplier, result, reward, convergence_iter'])\n",
    "for m_population in range(5, 21, 5): # population multiplier\n",
    "    for m_offsprings in range(5, 21, 5): # offsprings multiplier\n",
    "        config = {\n",
    "            'example_file': './examples/WTA2',\n",
    "            'population_size': N_WEAPONS * m_population,\n",
    "            'n_offsprings': N_WEAPONS * m_offsprings,\n",
    "            'm_c': 1,\n",
    "            'm_m': 1 # for fair comparison set m_m to 1\n",
    "        }\n",
    "        wta_1d = WTA_1D_General_GA(config, 2, mutation_method='random')\n",
    "        result, reward, convergence_iter = wta_1d.run(max_iter, verbose=False)\n",
    "        print('m_population: {}, m_offsprings: {} - result: {}, reward: {:.3f}, convergence: {}'.format(m_population, m_offsprings, result, reward, convergence_iter))\n",
    "        wr.writerow([m_population, m_offsprings, '_'.join(map(lambda x: str(x), result)), '{:.3f}'.format(reward), convergence_iter])\n",
    "        \n",
    "fpout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m_population: 5, m_offsprings: 5 - result: [6, 0, 2, 9, 4, 8, 1, 3, 9, 7], reward: 584.261, convergence: 3000\n",
      "m_population: 5, m_offsprings: 10 - result: [2, 8, 9, 6, 4, 0, 7, 3, 1, 3], reward: 597.863, convergence: 3000\n",
      "m_population: 5, m_offsprings: 15 - result: [0, 8, 7, 3, 4, 2, 1, 2, 9, 0], reward: 536.415, convergence: 82\n",
      "m_population: 5, m_offsprings: 20 - result: [3, 0, 9, 1, 4, 8, 7, 6, 2, 9], reward: 573.755, convergence: 3000\n",
      "m_population: 10, m_offsprings: 5 - result: [2, 8, 9, 6, 4, 0, 1, 7, 7, 3], reward: 596.992, convergence: 3000\n",
      "m_population: 10, m_offsprings: 10 - result: [3, 0, 2, 6, 4, 8, 1, 3, 9, 7], reward: 589.522, convergence: 3000\n",
      "m_population: 10, m_offsprings: 15 - result: [0, 8, 9, 6, 4, 2, 1, 7, 5, 3], reward: 603.224, convergence: 2762\n",
      "m_population: 10, m_offsprings: 20 - result: [0, 8, 9, 6, 4, 2, 1, 7, 5, 3], reward: 603.224, convergence: 2466\n",
      "m_population: 15, m_offsprings: 5 - result: [2, 8, 9, 6, 4, 0, 7, 3, 1, 3], reward: 597.863, convergence: 3000\n",
      "m_population: 15, m_offsprings: 10 - result: [3, 8, 5, 6, 4, 0, 1, 2, 9, 7], reward: 614.840, convergence: 3000\n",
      "m_population: 15, m_offsprings: 15 - result: [0, 8, 9, 6, 4, 2, 1, 3, 3, 7], reward: 596.746, convergence: 1041\n",
      "m_population: 15, m_offsprings: 20 - result: [0, 8, 9, 6, 4, 2, 1, 3, 3, 7], reward: 596.746, convergence: 3000\n",
      "m_population: 20, m_offsprings: 5 - result: [2, 8, 9, 6, 4, 0, 1, 3, 1, 7], reward: 601.777, convergence: 3000\n",
      "m_population: 20, m_offsprings: 10 - result: [5, 0, 3, 6, 4, 8, 1, 2, 9, 7], reward: 600.299, convergence: 3000\n",
      "m_population: 20, m_offsprings: 15 - result: [3, 8, 3, 6, 4, 0, 1, 2, 9, 7], reward: 600.383, convergence: 3000\n",
      "m_population: 20, m_offsprings: 20 - result: [2, 8, 9, 6, 4, 0, 1, 7, 7, 3], reward: 596.992, convergence: 2124\n"
     ]
    }
   ],
   "source": [
    "fpout = open('./experiments/WTA2/dqn_mutation.csv', 'w')\n",
    "wr = csv.writer(fpout, delimiter=',')\n",
    "wr.writerow(['population_multiplier, offsprings_multiplier, result, reward, convergence_iter])\n",
    "for m_population in range(5, 21, 5): # population multiplier\n",
    "    for m_offsprings in range(5, 21, 5): # offsprings multiplier\n",
    "        config = {\n",
    "            'example_file': './examples/WTA2',\n",
    "            'population_size': N_WEAPONS * m_population,\n",
    "            'n_offsprings': N_WEAPONS * m_offsprings,\n",
    "            'm_c': 1,\n",
    "            'm_m': 1 # for fair comparison set m_m to 1\n",
    "        }\n",
    "        wta_1d = WTA_1D_General_GA(config, 2, mutation_method='dqn')\n",
    "        result, reward, convergence_iter = wta_1d.run(max_iter, verbose=False)\n",
    "        print('m_population: {}, m_offsprings: {} - result: {}, reward: {:.3f}, convergence: {}'.format(m_population, m_offsprings, result, reward, convergence_iter))\n",
    "        wr.writerow([m_population, m_offsprings, '_'.join(map(lambda x: str(x), result)), '{:.3f}'.format(reward), convergence_iter])\n",
    "        \n",
    "fpout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m_population: 5, m_offsprings: 5 - result: [4, 3, 8, 2, 0, 9, 1, 7, 5, 6], reward: 553.869, convergence: 7\n",
      "m_population: 5, m_offsprings: 10 - result: [4, 3, 8, 2, 0, 9, 1, 7, 5, 6], reward: 553.869, convergence: 3\n",
      "m_population: 5, m_offsprings: 15 - result: [4, 3, 8, 2, 0, 9, 1, 7, 5, 6], reward: 553.869, convergence: 2\n",
      "m_population: 5, m_offsprings: 20 - result: [4, 3, 8, 2, 0, 9, 1, 7, 5, 6], reward: 553.869, convergence: 2\n",
      "m_population: 10, m_offsprings: 5 - result: [6, 8, 9, 2, 4, 0, 1, 7, 5, 3], reward: 603.382, convergence: 713\n",
      "m_population: 10, m_offsprings: 10 - result: [6, 8, 9, 2, 4, 0, 1, 7, 5, 3], reward: 603.382, convergence: 473\n",
      "m_population: 10, m_offsprings: 15 - result: [4, 3, 8, 2, 0, 9, 1, 7, 5, 6], reward: 553.869, convergence: 4\n",
      "m_population: 10, m_offsprings: 20 - result: [6, 8, 9, 2, 0, 4, 1, 7, 5, 3], reward: 601.917, convergence: 500\n",
      "m_population: 15, m_offsprings: 5 - result: [3, 8, 9, 6, 2, 0, 1, 4, 5, 7], reward: 616.805, convergence: 3000\n",
      "m_population: 15, m_offsprings: 10 - result: [6, 8, 9, 2, 4, 0, 1, 7, 5, 3], reward: 603.382, convergence: 503\n",
      "m_population: 15, m_offsprings: 15 - result: [6, 8, 9, 2, 4, 0, 1, 7, 5, 3], reward: 603.382, convergence: 571\n",
      "m_population: 15, m_offsprings: 20 - result: [6, 8, 9, 2, 0, 4, 1, 7, 5, 3], reward: 601.917, convergence: 175\n",
      "m_population: 20, m_offsprings: 5 - result: [6, 8, 9, 2, 4, 0, 1, 7, 5, 3], reward: 603.382, convergence: 2153\n",
      "m_population: 20, m_offsprings: 10 - result: [6, 8, 9, 2, 4, 0, 1, 7, 5, 3], reward: 603.382, convergence: 857\n",
      "m_population: 20, m_offsprings: 15 - result: [6, 8, 9, 2, 4, 0, 1, 7, 5, 3], reward: 603.382, convergence: 573\n",
      "m_population: 20, m_offsprings: 20 - result: [6, 8, 9, 2, 4, 0, 1, 7, 5, 3], reward: 603.382, convergence: 486\n"
     ]
    }
   ],
   "source": [
    "fpout = open('./experiments/WTA2/dueling_dqn_mutation.csv', 'w')\n",
    "wr = csv.writer(fpout, delimiter=',')\n",
    "wr.writerow(['population_multiplier, offsprings_multiplier, result, reward, convergence_iter])\n",
    "for m_population in range(5, 21, 5): # population multiplier\n",
    "    for m_offsprings in range(5, 21, 5): # offsprings multiplier\n",
    "        config = {\n",
    "            'example_file': './examples/WTA2',\n",
    "            'population_size': N_WEAPONS * m_population,\n",
    "            'n_offsprings': N_WEAPONS * m_offsprings,\n",
    "            'm_c': 1,\n",
    "            'm_m': 1 # for fair comparison set m_m to 1\n",
    "        }\n",
    "        wta_1d = WTA_1D_General_GA(config, 2, mutation_method='dueling_dqn')\n",
    "        result, reward, convergence_iter = wta_1d.run(max_iter, verbose=False)\n",
    "        print('m_population: {}, m_offsprings: {} - result: {}, reward: {:.3f}, convergence: {}'.format(m_population, m_offsprings, result, reward, convergence_iter))\n",
    "        wr.writerow([m_population, m_offsprings, '_'.join(map(lambda x: str(x), result)), '{:.3f}'.format(reward), convergence_iter])\n",
    "        \n",
    "fpout.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WTA3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_WEAPONS = 20\n",
    "max_iter = 5000\n",
    "N_WTA = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m_population: 5, m_offsprings: 5 - result: [2, 4, 17, 8, 1, 18, 5, 10, 7, 12, 3, 19, 13, 15, 11, 6, 9, 14, 16, 0], reward: 943.237, convergence: 5000\n",
      "m_population: 5, m_offsprings: 10 - result: [19, 6, 11, 9, 13, 10, 3, 17, 7, 12, 18, 14, 2, 0, 4, 15, 8, 5, 16, 1], reward: 937.955, convergence: 5000\n",
      "m_population: 5, m_offsprings: 15 - result: [11, 14, 17, 15, 6, 8, 12, 13, 2, 5, 18, 4, 16, 10, 0, 7, 0, 4, 6, 9], reward: 769.975, convergence: 731\n",
      "m_population: 5, m_offsprings: 20 - result: [0, 9, 17, 16, 10, 10, 9, 8, 14, 12, 4, 13, 11, 11, 8, 3, 5, 7, 2, 7], reward: 779.508, convergence: 620\n",
      "m_population: 10, m_offsprings: 5 - result: [6, 1, 2, 9, 3, 18, 5, 10, 7, 12, 15, 19, 13, 4, 11, 17, 8, 0, 16, 14], reward: 952.597, convergence: 5000\n",
      "m_population: 10, m_offsprings: 10 - result: [4, 8, 5, 9, 1, 3, 2, 13, 7, 6, 10, 18, 14, 12, 11, 17, 19, 0, 15, 16], reward: 940.441, convergence: 5000\n",
      "m_population: 10, m_offsprings: 15 - result: [2, 6, 11, 9, 15, 3, 5, 8, 10, 19, 4, 18, 13, 7, 1, 17, 14, 0, 16, 12], reward: 945.016, convergence: 5000\n",
      "m_population: 10, m_offsprings: 20 - result: [2, 8, 7, 9, 16, 3, 19, 1, 10, 0, 17, 18, 13, 4, 11, 6, 14, 5, 15, 12], reward: 945.322, convergence: 5000\n",
      "m_population: 15, m_offsprings: 5 - result: [18, 1, 9, 8, 16, 10, 5, 17, 7, 6, 3, 4, 19, 12, 11, 13, 14, 0, 15, 2], reward: 937.739, convergence: 5000\n",
      "m_population: 15, m_offsprings: 10 - result: [6, 1, 11, 9, 13, 18, 5, 10, 7, 12, 17, 19, 2, 0, 4, 3, 8, 14, 15, 16], reward: 947.742, convergence: 5000\n",
      "m_population: 15, m_offsprings: 15 - result: [11, 8, 2, 9, 3, 10, 5, 17, 7, 12, 18, 19, 13, 4, 1, 6, 14, 0, 15, 16], reward: 955.495, convergence: 5000\n",
      "m_population: 15, m_offsprings: 20 - result: [2, 8, 11, 9, 15, 18, 5, 10, 7, 6, 17, 12, 13, 0, 4, 3, 14, 19, 16, 1], reward: 949.743, convergence: 5000\n",
      "m_population: 20, m_offsprings: 5 - result: [5, 8, 11, 9, 18, 10, 3, 1, 7, 12, 17, 19, 13, 15, 4, 6, 14, 0, 16, 2], reward: 937.354, convergence: 5000\n",
      "m_population: 20, m_offsprings: 10 - result: [11, 1, 17, 9, 4, 19, 5, 8, 10, 12, 3, 18, 13, 0, 15, 6, 14, 7, 16, 2], reward: 947.526, convergence: 5000\n",
      "m_population: 20, m_offsprings: 15 - result: [2, 1, 17, 9, 19, 18, 5, 10, 7, 6, 3, 4, 13, 12, 11, 0, 8, 14, 15, 16], reward: 950.749, convergence: 5000\n",
      "m_population: 20, m_offsprings: 20 - result: [2, 1, 11, 12, 3, 18, 5, 13, 10, 6, 7, 19, 14, 4, 9, 17, 8, 0, 15, 16], reward: 951.100, convergence: 5000\n"
     ]
    }
   ],
   "source": [
    "fpout = open('./experiments/WTA{}/random_mutation.csv'.format(N_WTA), 'w')\n",
    "wr = csv.writer(fpout, delimiter=',')\n",
    "wr.writerow(['population_multiplier, offsprings_multiplier, result, reward, convergence_iter'])\n",
    "for m_population in range(5, 21, 5): # population multiplier\n",
    "    for m_offsprings in range(5, 21, 5): # offsprings multiplier\n",
    "        config = {\n",
    "            'example_file': './examples/WTA{}'.format(N_WTA),\n",
    "            'population_size': N_WEAPONS * m_population,\n",
    "            'n_offsprings': N_WEAPONS * m_offsprings,\n",
    "            'm_c': 1,\n",
    "            'm_m': 1 # for fair comparison set m_m to 1\n",
    "        }\n",
    "        wta_1d = WTA_1D_General_GA(config, N_WTA, mutation_method='random')\n",
    "        result, reward, convergence_iter = wta_1d.run(max_iter, verbose=False)\n",
    "        print('m_population: {}, m_offsprings: {} - result: {}, reward: {:.3f}, convergence: {}'.format(m_population, m_offsprings, result, reward, convergence_iter))\n",
    "        wr.writerow([m_population, m_offsprings, '_'.join(map(lambda x: str(x), result)), '{:.3f}'.format(reward), convergence_iter])\n",
    "        \n",
    "fpout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m_population: 5, m_offsprings: 5 - result: [19, 6, 17, 10, 3, 18, 16, 11, 14, 12, 5, 4, 0, 15, 1, 2, 8, 7, 9, 13], reward: 892.151, convergence: 22\n",
      "m_population: 5, m_offsprings: 10 - result: [19, 6, 17, 10, 3, 18, 16, 11, 14, 12, 5, 4, 0, 15, 1, 2, 8, 7, 9, 13], reward: 892.151, convergence: 7\n",
      "m_population: 5, m_offsprings: 15 - result: [19, 6, 17, 10, 3, 18, 16, 11, 14, 12, 5, 4, 0, 15, 1, 2, 8, 7, 9, 13], reward: 892.151, convergence: 4\n",
      "m_population: 5, m_offsprings: 20 - result: [19, 6, 17, 10, 3, 18, 16, 11, 14, 12, 5, 4, 0, 15, 1, 2, 8, 7, 9, 13], reward: 892.151, convergence: 4\n",
      "m_population: 10, m_offsprings: 5 - result: [19, 6, 17, 9, 3, 10, 5, 13, 7, 12, 18, 4, 2, 15, 11, 0, 8, 14, 16, 1], reward: 944.753, convergence: 5000\n",
      "m_population: 10, m_offsprings: 10 - result: [19, 6, 17, 10, 3, 18, 16, 11, 14, 12, 5, 4, 0, 15, 1, 2, 8, 7, 9, 13], reward: 892.151, convergence: 18\n",
      "m_population: 10, m_offsprings: 15 - result: [19, 6, 17, 10, 3, 18, 16, 11, 14, 12, 5, 4, 0, 15, 1, 2, 8, 7, 9, 13], reward: 892.151, convergence: 10\n",
      "m_population: 10, m_offsprings: 20 - result: [19, 6, 17, 10, 3, 18, 16, 11, 14, 12, 5, 4, 0, 15, 1, 2, 8, 7, 9, 13], reward: 892.151, convergence: 6\n",
      "m_population: 15, m_offsprings: 5 - result: [19, 6, 2, 9, 3, 18, 5, 13, 10, 12, 17, 4, 14, 15, 11, 0, 8, 7, 16, 1], reward: 948.175, convergence: 5000\n",
      "m_population: 15, m_offsprings: 10 - result: [19, 6, 2, 9, 3, 18, 5, 1, 10, 12, 14, 4, 13, 0, 11, 17, 8, 7, 15, 16], reward: 950.499, convergence: 5000\n",
      "m_population: 15, m_offsprings: 15 - result: [19, 6, 17, 10, 3, 18, 16, 11, 14, 12, 5, 4, 0, 15, 1, 2, 8, 7, 9, 13], reward: 892.151, convergence: 20\n",
      "m_population: 15, m_offsprings: 20 - result: [19, 6, 17, 10, 3, 18, 16, 11, 14, 12, 5, 4, 0, 15, 1, 2, 8, 7, 9, 13], reward: 892.151, convergence: 11\n",
      "m_population: 20, m_offsprings: 5 - result: [19, 2, 17, 9, 3, 18, 5, 1, 10, 12, 7, 4, 13, 15, 11, 6, 8, 0, 14, 16], reward: 943.906, convergence: 5000\n",
      "m_population: 20, m_offsprings: 10 - result: [19, 6, 2, 9, 3, 18, 5, 1, 10, 12, 14, 4, 13, 0, 11, 17, 8, 7, 15, 16], reward: 950.499, convergence: 5000\n",
      "m_population: 20, m_offsprings: 15 - result: [19, 6, 2, 9, 16, 18, 5, 13, 10, 12, 3, 4, 14, 0, 11, 17, 8, 7, 15, 1], reward: 952.806, convergence: 5000\n",
      "m_population: 20, m_offsprings: 20 - result: [19, 6, 17, 10, 3, 18, 16, 11, 14, 12, 5, 4, 0, 15, 1, 2, 8, 7, 9, 13], reward: 892.151, convergence: 18\n"
     ]
    }
   ],
   "source": [
    "fpout = open('./experiments/WTA{}/dqn_mutation.csv'.format(N_WTA), 'w')\n",
    "wr = csv.writer(fpout, delimiter=',')\n",
    "wr.writerow(['population_multiplier', 'offsprings_multiplier', 'result', 'reward', 'convergence_iter'])\n",
    "for m_population in range(5, 21, 5): # population multiplier\n",
    "    for m_offsprings in range(5, 21, 5): # offsprings multiplier\n",
    "        config = {\n",
    "            'example_file': './examples/WTA{}'.format(N_WTA),\n",
    "            'population_size': N_WEAPONS * m_population,\n",
    "            'n_offsprings': N_WEAPONS * m_offsprings,\n",
    "            'm_c': 1,\n",
    "            'm_m': 1 # for fair comparison set m_m to 1\n",
    "        }\n",
    "        wta_1d = WTA_1D_General_GA(config, N_WTA, mutation_method='dqn')\n",
    "        result, reward, convergence_iter = wta_1d.run(max_iter, verbose=False)\n",
    "        print('m_population: {}, m_offsprings: {} - result: {}, reward: {:.3f}, convergence: {}'.format(m_population, m_offsprings, result, reward, convergence_iter))\n",
    "        wr.writerow([m_population, m_offsprings, '_'.join(map(lambda x: str(x), result)), '{:.3f}'.format(reward), convergence_iter])\n",
    "        \n",
    "fpout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m_population: 5, m_offsprings: 5 - result: [19, 0, 5, 11, 4, 2, 13, 1, 10, 15, 3, 12, 14, 8, 17, 6, 18, 9, 7, 16], reward: 876.899, convergence: 18\n",
      "m_population: 5, m_offsprings: 10 - result: [19, 0, 5, 11, 4, 2, 13, 1, 10, 15, 3, 12, 14, 8, 17, 6, 18, 9, 7, 16], reward: 876.899, convergence: 4\n",
      "m_population: 5, m_offsprings: 15 - result: [19, 0, 5, 11, 4, 2, 13, 1, 10, 15, 3, 12, 14, 8, 17, 6, 18, 9, 7, 16], reward: 876.899, convergence: 3\n",
      "m_population: 5, m_offsprings: 20 - result: [19, 0, 5, 11, 4, 2, 13, 1, 10, 15, 3, 12, 14, 8, 17, 6, 18, 9, 7, 16], reward: 876.899, convergence: 2\n",
      "m_population: 10, m_offsprings: 5 - result: [19, 1, 5, 9, 18, 2, 4, 13, 10, 6, 3, 12, 14, 0, 11, 17, 8, 7, 15, 16], reward: 951.467, convergence: 5000\n",
      "m_population: 10, m_offsprings: 10 - result: [19, 0, 5, 11, 4, 2, 13, 1, 10, 15, 3, 12, 14, 8, 17, 6, 18, 9, 7, 16], reward: 876.899, convergence: 12\n",
      "m_population: 10, m_offsprings: 15 - result: [19, 0, 5, 11, 4, 2, 13, 1, 10, 15, 3, 12, 14, 8, 17, 6, 18, 9, 7, 16], reward: 876.899, convergence: 5\n",
      "m_population: 10, m_offsprings: 20 - result: [19, 0, 5, 11, 4, 2, 13, 1, 10, 15, 3, 12, 14, 8, 17, 6, 18, 9, 7, 16], reward: 876.899, convergence: 4\n",
      "m_population: 15, m_offsprings: 5 - result: [19, 1, 5, 18, 17, 2, 3, 13, 10, 0, 4, 12, 14, 9, 11, 6, 8, 7, 16, 17], reward: 937.026, convergence: 5000\n",
      "m_population: 15, m_offsprings: 10 - result: [19, 1, 5, 9, 18, 2, 3, 13, 10, 6, 4, 12, 14, 0, 11, 17, 8, 7, 15, 16], reward: 952.873, convergence: 5000\n",
      "m_population: 15, m_offsprings: 15 - result: [19, 1, 5, 9, 18, 2, 3, 13, 10, 0, 17, 12, 14, 4, 11, 6, 8, 7, 15, 16], reward: 953.059, convergence: 5000\n",
      "m_population: 15, m_offsprings: 20 - result: [19, 0, 5, 11, 4, 2, 13, 1, 10, 15, 3, 12, 14, 8, 17, 6, 18, 9, 7, 16], reward: 876.899, convergence: 7\n",
      "m_population: 20, m_offsprings: 5 - result: [19, 7, 5, 9, 1, 2, 3, 13, 10, 6, 18, 12, 14, 4, 11, 17, 8, 0, 16, 17], reward: 938.445, convergence: 5000\n",
      "m_population: 20, m_offsprings: 10 - result: [19, 1, 5, 9, 18, 2, 17, 13, 10, 0, 3, 12, 14, 4, 11, 6, 8, 7, 15, 16], reward: 949.977, convergence: 5000\n",
      "m_population: 20, m_offsprings: 15 - result: [19, 1, 5, 18, 3, 2, 4, 13, 10, 0, 17, 12, 14, 9, 11, 6, 8, 7, 15, 16], reward: 949.489, convergence: 5000\n",
      "m_population: 20, m_offsprings: 20 - result: [19, 0, 5, 11, 4, 2, 13, 1, 10, 15, 3, 12, 14, 8, 17, 6, 18, 9, 7, 16], reward: 876.899, convergence: 9\n"
     ]
    }
   ],
   "source": [
    "fpout = open('./experiments/WTA{}/dueling_dqn_mutation.csv'.format(N_WTA), 'w')\n",
    "wr = csv.writer(fpout, delimiter=',')\n",
    "wr.writerow(['population_multiplier', 'offsprings_multiplier', 'result', 'reward', 'convergence_iter'])\n",
    "for m_population in range(5, 21, 5): # population multiplier\n",
    "    for m_offsprings in range(5, 21, 5): # offsprings multiplier\n",
    "        config = {\n",
    "            'example_file': './examples/WTA{}'.format(N_WTA),\n",
    "            'population_size': N_WEAPONS * m_population,\n",
    "            'n_offsprings': N_WEAPONS * m_offsprings,\n",
    "            'm_c': 1,\n",
    "            'm_m': 1 # for fair comparison set m_m to 1\n",
    "        }\n",
    "        wta_1d = WTA_1D_General_GA(config, N_WTA, mutation_method='dueling_dqn')\n",
    "        result, reward, convergence_iter = wta_1d.run(max_iter, verbose=False)\n",
    "        print('m_population: {}, m_offsprings: {} - result: {}, reward: {:.3f}, convergence: {}'.format(m_population, m_offsprings, result, reward, convergence_iter))\n",
    "        wr.writerow([m_population, m_offsprings, '_'.join(map(lambda x: str(x), result)), '{:.3f}'.format(reward), convergence_iter])\n",
    "        \n",
    "fpout.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions\n",
    "\n",
    "1. What happens if m_m or m_c larger than 1 - not much difference for WTA1 and WTA2\n",
    "2. Look into what happens when the program hits maximum iter\n",
    "3. Choose one m_population and m_offsprings and increase max_iter\n",
    "4. Compare using the same number of convergence instead of until it reaches convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
